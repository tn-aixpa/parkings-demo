{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "\n",
    "### 1.1. Download data\n",
    "Download data from the API, and load it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://opendata.comune.bologna.it/api/explore/v2.1/catalog/datasets/disponibilita-parcheggi-storico/exports/csv?lang=it&timezone=UTC&use_labels=true&delimiter=%3B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Platform Support - Data Ops\n",
    "\n",
    "We use the platform support to load the data into the platform, version it, and automate the execution of the data management operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Initalization\n",
    "Create the working context: data management project for the parking data processing. Project is a placeholder for the code, data, and management of the parking data operations. To keep it reproducible, we use the `git` source type to store the definition and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_funtion_complete(rrun,seconds = 1,status =False):\n",
    "    import time\n",
    "    rrun.refresh()\n",
    "    state = rrun.status\n",
    "    #print(state)\n",
    "    v = 0\n",
    "    while state.state =='READY' or state.state =='RUNNING':\n",
    "        print(f\"Seconds: {v}, {'status: '+ state.state if status else ''} ...\")\n",
    "        v+=seconds\n",
    "        rrun.refresh()\n",
    "        state = rrun.status\n",
    "        time.sleep(seconds)\n",
    "    print(f\"Finished at {v} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "\n",
    "PROJECT_NAME = \"MLparksrem\"\n",
    "proj = dh.get_or_create_project(PROJECT_NAME) # source=\"git://github.com/scc-digitalhub/gdb-project-parkings.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data management functions\n",
    "We convert the data management ETL operations into functions - single executable operations that can be executed in the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting download_all_dh_core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"download_all_dh_core.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"dataset\"])\n",
    "def downloader(project, url):\n",
    "    df = url.as_df(file_format='csv',sep=\";\")\n",
    "    df[['lat', 'lon']] = df['coordinate'].str.split(', ',expand=True)\n",
    "    df = df.drop(columns=['% occupazione', 'GUID', 'coordinate']).rename(columns={'Parcheggio': 'parcheggio', 'Data': 'data', 'Posti liberi': 'posti_liberi', 'Posti occupati': 'posti_occupati', 'Posti totali': 'posti_totali'})\n",
    "    df[\"lat\"] = pd.to_numeric(df[\"lat\"])\n",
    "    df[\"lon\"] = pd.to_numeric(df[\"lon\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"downloader-funct\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"download_all_dh_core.py\", \"handler\": \"downloader\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "di= proj.new_dataitem(name=\"url_data_item\",kind=\"table\",path=URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download = func.run(action=\"job\",inputs={\"url\":di.key},outputs={\"dataset\":\"dataset\"})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds: 0,  ...\n",
      "Seconds: 10,  ...\n",
      "Seconds: 20,  ...\n",
      "Seconds: 30,  ...\n",
      "Seconds: 40,  ...\n",
      "Finished at 50 seconds\n"
     ]
    }
   ],
   "source": [
    "running_funtion_complete(run_download,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_download.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'store://MLparksrem/dataitems/table/dataset:bd41046b-b3e4-448e-8c6a-322fcce08099'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item_download  = dh.get_dataitem(project=PROJECT_NAME,entity_name=\"dataset\").key\n",
    "data_item_download  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_item_download = proj.new_dataitem(name=\"dataset\", kind=\"table\", path=\"s3://datalake/parcheggi/dataitems/f2024e9f-6dda-4a77-9216-80713b881300/data.parquet\")#run_download.outputs()['dataset'].key\n",
    "#data_item_download = data_item_download.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting extract_parkings_dh_core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"extract_parkings_dh_core.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"parkings\"])\n",
    "def extract_parkings(project, di):\n",
    "    KEYS = ['parcheggio', 'lat', 'lon', 'posti_totali']\n",
    "    df_parcheggi = di.as_df().groupby(['parcheggio']).first().reset_index()[KEYS]\n",
    "    return df_parcheggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"extract-parkings\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"extract_parkings_dh_core.py\", \"handler\": \"extract_parkings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_parkings = func.run(action=\"job\",inputs={\"di\":data_item_download},outputs={\"parkings\":\"parkings\"})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds: 0,  ...\n",
      "Seconds: 10,  ...\n",
      "Seconds: 20,  ...\n",
      "Seconds: 30,  ...\n",
      "Seconds: 40,  ...\n",
      "Seconds: 50,  ...\n",
      "Finished at 60 seconds\n"
     ]
    }
   ],
   "source": [
    "running_funtion_complete(run_parkings,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'store://MLparksrem/dataitems/table/parkings:9c8d0beb-104f-4a67-98a1-c11d0f4d7d9d'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item_parkings = dh.get_dataitem(project=PROJECT_NAME,entity_name=\"parkings\").key\n",
    "data_item_parkings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting aggregations_parkings_dh_core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"aggregations_parkings_dh_core.py\"\n",
    "from datetime import datetime\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"parking_data_aggregated\"])\n",
    "def aggregate_parkings(project, di):\n",
    "    rdf = di.as_df()\n",
    "    rdf['data'] = pd.to_datetime(rdf['data'])\n",
    "    rdf['day'] = rdf['data'].apply(lambda t: t.replace(second=0, minute=0))\n",
    "    rdf['hour'] = rdf['day'].dt.hour\n",
    "    rdf['dow'] = rdf['day'].dt.dayofweek\n",
    "    #rdf['type'] = rdf['data']#.apply(lambda t: \"sadassad\"+t.astype(str))\n",
    "    rdf['day'] = rdf['day'].apply(lambda t: datetime.timestamp(t)) #added because complain of timestamp not JSOn serializable#\n",
    "    rdf = rdf.drop(columns=['data'])\n",
    "    rdf['lat'] = rdf['lat'].apply(lambda t: float(t))\n",
    "    rdf['lon'] = rdf['lon'].apply(lambda t: float(t))\n",
    "    grouped = rdf.groupby(['parcheggio','day']).mean() #\n",
    "    df_aggregated = grouped.reset_index()\n",
    "    return df_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"aggregate-parkings\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"aggregations_parkings_dh_core.py\", \"handler\": \"aggregate_parkings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data_item = run.outputs()['dataset'].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_aggregate = func.run(action=\"job\",inputs={\"di\":data_item_download},outputs={\"parking_data_aggregated\":\"parking_data_aggregated\"})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds: 0,  ...\n",
      "Seconds: 10,  ...\n",
      "Seconds: 20,  ...\n",
      "Seconds: 30,  ...\n",
      "Seconds: 40,  ...\n",
      "Seconds: 50,  ...\n",
      "Finished at 60 seconds\n"
     ]
    }
   ],
   "source": [
    "running_funtion_complete(run_aggregate,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'store://MLparksrem/dataitems/table/parking_data_aggregated:cdfee7db-4080-4bdc-98e3-4cf1807d17c8'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item_aggregate = dh.get_dataitem(project=PROJECT_NAME,entity_name=\"parking_data_aggregated\").key\n",
    "data_item_aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_aggregate.outputs()['parking_data_aggregated'].as_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digitalhub_owner_user jCU2ILsYX1GoCnHE1WLjJjjWGfUkodum9H9sAcs5B3eB5QmJ6mOvyoTj73qTwmhg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"POSTGRES_USER\"),os.getenv(\"POSTGRES_PASSWORD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting parkings_to_db.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"parkings_to_db.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import datetime as dtt\n",
    "import os\n",
    "\n",
    "@handler()\n",
    "def to_db(project, agg_di , parkings_di ):\n",
    "    USERNAME = os.getenv(\"POSTGRES_USER\")#project.get_secret(entity_name='DB_USERNAME').read_secret_value()\n",
    "    PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")#project.get_secret(entity_name='DB_PASSWORD').read_secret_value()\n",
    "    engine = create_engine('postgresql+psycopg2://'+USERNAME+':'+PASSWORD+'@database-postgres-cluster/digitalhub')\n",
    "    \n",
    "    agg_df = agg_di.as_df(file_format=\"parquet\")\n",
    "        \n",
    "    # Keep only last two calendar years\n",
    "    date = dtt.date.today() - dtt.timedelta(days=365*2)\n",
    "    agg_df['day'] = agg_df['day'].apply(lambda t: datetime.fromtimestamp(t)) #added because before was converted the type\n",
    "    agg_df = agg_df[agg_df['day'].dt.date >= date]\n",
    "    agg_df.to_sql(\"parking_data_aggregated\", engine, if_exists=\"replace\")\n",
    "    parkings_di.as_df().to_sql('parkings', engine, if_exists=\"replace\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"to-db\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         requirements=[\"sqlalchemy\"],\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"parkings_to_db.py\", \"handler\": \"to_db\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set secrets\n",
    "#print(os.getenv(\"POSTGRES_USER\"),os.getenv(\"POSTGRES_PASSWORD\"))\n",
    "#user = os.getenv(\"POSTGRES_USER\")\n",
    "#password = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "#secret_a = proj.new_secret(name=\"DB_USERNAME_NEW\", secret_value=user)\n",
    "#secret_b = proj.new_secret(name=\"DB_PASSWORD\", secret_value=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N:B; this might get stuck for some low RAM issues \n",
    "run_to_db = func.run(action=\"job\",inputs={\"agg_di\":data_item_aggregate,\"parkings_di\":data_item_parkings},outputs={})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds: 0,  ...\n",
      "Seconds: 10,  ...\n",
      "Seconds: 20,  ...\n",
      "Seconds: 30,  ...\n",
      "Seconds: 40,  ...\n",
      "Seconds: 50,  ...\n",
      "Finished at 60 seconds\n"
     ]
    }
   ],
   "source": [
    "running_funtion_complete(run_to_db,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Management Pipeline\n",
    "We create a data management pipeline that executes the data management functions in the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting parkings_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"parkings_pipeline.py\"\n",
    "\n",
    "from digitalhub_runtime_kfp.dsl import pipeline_context\n",
    "\n",
    "def myhandler(url):\n",
    "    with pipeline_context() as pc:\n",
    "        s1_dataset = pc.step(name=\"download\", function=\"downloader-funct\", action=\"job\",inputs={\"url\":url},outputs={\"dataset\":\"dataset\"})\n",
    "        #data_item_download = s1_dataset.outputs()[‘dataset’].key\n",
    "        \n",
    "        s2_parking = pc.step(name=\"extract_parking\", function=\"extract-parkings\", action=\"job\",inputs={\"di\":s1_dataset.outputs['dataset']},outputs={\"parkings\":\"parkings\"})\n",
    "        \n",
    "        s3_aggregate = pc.step(name=\"aggregate\",  function=\"aggregate-parkings\", action=\"job\",inputs={\"di\":s1_dataset.outputs['dataset']},outputs={\"parking_data_aggregated\":\"parking_data_aggregated\"})\n",
    "        #data_item_aggregate = s3_aggregate.outputs()[‘parking_data_aggregated’].key\n",
    "        \n",
    "        s4_to_db = pc.step(name=\"to_db\",  function=\"to-db\", action=\"job\",inputs={\"agg_di\": s3_aggregate.outputs['parking_data_aggregated'],\"parkings_di\":s1_dataset.outputs['dataset']},outputs={})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = proj.new_workflow(name=\"pipeline_parcheggi\", kind=\"kfp\", source={\"source\": \"parkings_pipeline.py\"}, handler=\"myhandler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "di= proj.new_dataitem(name=\"url_data_item\",kind=\"table\",path=URL)\n",
    "workflow_run = workflow.run(parameters={\"url\": di.key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "\n",
    "PROJECT_NAME = \"MLparksrem\"\n",
    "ml_proj = dh.get_or_create_project(PROJECT_NAME) # source=\"git://github.com/scc-digitalhub/gdb-project-parkings.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_multimodel.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"train_multimodel.py\"\n",
    "\n",
    "import pandas as pd\n",
    "from digitalhub_runtime_python import handler\n",
    "from darts import TimeSeries\n",
    "\n",
    "from darts.models import NBEATSModel\n",
    "from darts.metrics import mape, smape, mae\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from pickle import dumps\n",
    "\n",
    "def fill_missing(parc_df):\n",
    "    missing = []  # List to store timestamps for which values could not be filled\n",
    "    temp = pd.Series(parc_df.index.date).value_counts()  # Count the occurrences of each date\n",
    "    temp = temp[temp < 48]  # Filter dates with less than 48 occurrences\n",
    "    temp.sort_index(inplace=True)  # Sort the dates in ascending order\n",
    "    for t in temp.index:  # Iterate through the filtered dates\n",
    "        for h in range(24):  # Iterate through 24 hours\n",
    "            for half_hour in [0, 30]:  # Iterate through 0 and 30 minutes\n",
    "                ts = datetime.datetime(t.year, t.month, t.day, h, half_hour)  # Create a timestamp\n",
    "                if ts not in parc_df.index:  # If the timestamp is missing in the DataFrame\n",
    "                    if ts - datetime.timedelta(days=7) in parc_df.index:  # Check if the previous week's timestamp is available\n",
    "                        parc_df.loc[ts] = parc_df.loc[ts - datetime.timedelta(days=7)].copy()  # Copy values from the previous week\n",
    "                    elif ts + datetime.timedelta(days=7) in parc_df.index:  # Check if the next week's timestamp is available\n",
    "                        parc_df.loc[ts] = parc_df.loc[ts + datetime.timedelta(days=7)].copy()  # Copy values from the next week\n",
    "                    else:\n",
    "                        missing.append(ts)  # If values cannot be filled, add the timestamp to the missing list\n",
    "    return missing  # Return the list of timestamps for which values could not be filled\n",
    "\n",
    "\n",
    "@handler()\n",
    "def train_model(project, parkings_di,n_epochs: int = 1, window: int = 60, \n",
    "                input_chunk_length: int = 24, output_chunk_length: int = 12, \n",
    "                split_ratio: float = 0.8):\n",
    "\n",
    "    # Load the input data\n",
    "    df_source = parkings_di.as_df()\n",
    "    # Clean the data\n",
    "    df_clean = df_source.copy()\n",
    "    df_clean.data = pd.to_datetime(df_clean.data, utc=True)\n",
    "    df_clean['occupied'] = df_clean.posti_occupati / df_clean.posti_totali\n",
    "    df_clean['date_time_slice'] = df_clean.data.dt.round('30min').dt.tz_convert(None)\n",
    "    df_clean = df_clean[df_clean.date_time_slice >= (datetime.datetime.today() - pd.DateOffset(window))]\n",
    "    df_clean = df_clean[df_clean.date_time_slice <= (datetime.datetime.today() - pd.DateOffset(1))]\n",
    "    df_clean.posti_occupati = df_clean.apply(lambda x: max(0, min(x['posti_totali'], x['posti_occupati'])), axis=1)\n",
    "    df_clean['occupied'] = df_clean.posti_occupati / df_clean.posti_totali\n",
    "    df_clean = df_clean.drop(columns=['lat', 'lon', 'data', 'posti_totali', 'posti_liberi', 'posti_occupati'])\n",
    "    parcheggi = df_clean['parcheggio'].unique()\n",
    "\n",
    "    train_sets, val_sets = [], []\n",
    "\n",
    "    # Process data for each parking lot\n",
    "    for parcheggio in parcheggi:\n",
    "        parc_df = df_clean[df_clean['parcheggio'] == parcheggio]\n",
    "        parc_df['hour'] = parc_df.date_time_slice.dt.hour\n",
    "        parc_df['dow'] = parc_df.date_time_slice.dt.dayofweek\n",
    "        parc_df = parc_df.drop(columns=['parcheggio'])\n",
    "        parc_df = parc_df.groupby('date_time_slice').agg({'occupied': 'mean', 'hour': 'first', 'dow': 'first'})\n",
    "        fill_missing(parc_df)\n",
    "        ts = TimeSeries.from_dataframe(parc_df,  value_cols='occupied', freq='30min')\n",
    "        ts_scaled = Scaler().fit_transform(ts)\n",
    "        \n",
    "        split = int(len(ts_scaled) * (1 - split_ratio))\n",
    "\n",
    "        # Split data into training and validation sets\n",
    "        train, val = ts_scaled[:-split], ts_scaled[-split:]\n",
    "        train_sets.append(train)\n",
    "        val_sets.append(val)\n",
    "\n",
    "    # Train a multi-model using the NBEATS algorithm\n",
    "    multimodel =  NBEATSModel(\n",
    "        input_chunk_length=input_chunk_length,\n",
    "        output_chunk_length=output_chunk_length,\n",
    "        n_epochs=n_epochs,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Fit the model to the training sets\n",
    "    multimodel.fit(train_sets)\n",
    "    pred = multimodel.predict(n=output_chunk_length*2, series=train_sets[0][:-output_chunk_length*2])\n",
    "\n",
    "    multimodel.save(\"parcheggi_predictor_model.pt\")\n",
    "    with ZipFile(\"parcheggi_predictor_model.pt.zip\", \"w\") as z:\n",
    "        z.write(\"parcheggi_predictor_model.pt\")\n",
    "        z.write(\"parcheggi_predictor_model.pt.ckpt\")\n",
    "    project.log_model(name=\"modelloparcheggi\", kind=\"model\", source_path=\"parcheggi_predictor_model.pt.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"training_model\"\n",
    "func = ml_proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         requirements =[\"darts==0.25.0\", \"pandas==1.4.4\", \"numpy==1.22.4\", \"patsy==0.5.2\", \"scikit-learn==1.1.2\"],\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         base_image = \"python:3.9\",\n",
    "                         source={\"source\": \"train_multimodel.py\", \"handler\": \"train_model\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'store://MLparksrem/dataitems/table/dataset:bd41046b-b3e4-448e-8c6a-322fcce08099'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_item_download # relative to the parkings above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_build_model = func.run(action=\"build\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds: 0, status: READY ...\n",
      "Seconds: 10, status: READY ...\n",
      "Seconds: 20, status: RUNNING ...\n",
      "Seconds: 30, status: RUNNING ...\n",
      "Seconds: 40, status: RUNNING ...\n",
      "Seconds: 50, status: RUNNING ...\n",
      "Seconds: 60, status: RUNNING ...\n",
      "Seconds: 70, status: RUNNING ...\n",
      "Seconds: 80, status: RUNNING ...\n",
      "Seconds: 90, status: RUNNING ...\n",
      "Seconds: 100, status: RUNNING ...\n",
      "Seconds: 110, status: RUNNING ...\n",
      "Seconds: 120, status: RUNNING ...\n",
      "Seconds: 130, status: RUNNING ...\n",
      "Seconds: 140, status: RUNNING ...\n",
      "Seconds: 150, status: RUNNING ...\n",
      "Seconds: 160, status: RUNNING ...\n",
      "Seconds: 170, status: RUNNING ...\n",
      "Seconds: 180, status: RUNNING ...\n",
      "Seconds: 190, status: RUNNING ...\n",
      "Seconds: 200, status: RUNNING ...\n",
      "Seconds: 210, status: RUNNING ...\n",
      "Seconds: 220, status: RUNNING ...\n",
      "Seconds: 230, status: RUNNING ...\n",
      "Seconds: 240, status: RUNNING ...\n",
      "Seconds: 250, status: RUNNING ...\n",
      "Seconds: 260, status: RUNNING ...\n",
      "Seconds: 270, status: RUNNING ...\n",
      "Seconds: 280, status: RUNNING ...\n",
      "Seconds: 290, status: RUNNING ...\n",
      "Seconds: 300, status: RUNNING ...\n",
      "Seconds: 310, status: RUNNING ...\n",
      "Seconds: 320, status: RUNNING ...\n",
      "Seconds: 330, status: RUNNING ...\n",
      "Seconds: 340, status: RUNNING ...\n",
      "Seconds: 350, status: RUNNING ...\n",
      "Seconds: 360, status: RUNNING ...\n",
      "Seconds: 370, status: RUNNING ...\n",
      "Seconds: 380, status: RUNNING ...\n",
      "Seconds: 390, status: RUNNING ...\n",
      "Seconds: 400, status: RUNNING ...\n",
      "Seconds: 410, status: RUNNING ...\n",
      "Seconds: 420, status: RUNNING ...\n",
      "Seconds: 430, status: RUNNING ...\n",
      "Seconds: 440, status: RUNNING ...\n",
      "Seconds: 450, status: RUNNING ...\n",
      "Seconds: 460, status: RUNNING ...\n",
      "Seconds: 470, status: RUNNING ...\n",
      "Seconds: 480, status: RUNNING ...\n",
      "Seconds: 490, status: RUNNING ...\n",
      "Seconds: 500, status: RUNNING ...\n",
      "Seconds: 510, status: RUNNING ...\n",
      "Seconds: 520, status: RUNNING ...\n",
      "Seconds: 530, status: RUNNING ...\n",
      "Seconds: 540, status: RUNNING ...\n",
      "Finished at 550 seconds\n"
     ]
    }
   ],
   "source": [
    "running_funtion_complete(run_build_model,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_train_model = func.run(action=\"job\",inputs={\"parkings_di\":data_item_download},outputs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds: 0, status: READY ...\n",
      "Seconds: 10, status: READY ...\n",
      "Seconds: 20, status: RUNNING ...\n",
      "Seconds: 30, status: RUNNING ...\n",
      "Seconds: 40, status: RUNNING ...\n",
      "Seconds: 50, status: RUNNING ...\n",
      "Seconds: 60, status: RUNNING ...\n",
      "Seconds: 70, status: RUNNING ...\n",
      "Seconds: 80, status: RUNNING ...\n",
      "Seconds: 90, status: RUNNING ...\n",
      "Seconds: 100, status: RUNNING ...\n",
      "Seconds: 110, status: RUNNING ...\n",
      "Seconds: 120, status: RUNNING ...\n",
      "Seconds: 130, status: RUNNING ...\n",
      "Seconds: 140, status: RUNNING ...\n",
      "Seconds: 150, status: RUNNING ...\n",
      "Seconds: 160, status: RUNNING ...\n",
      "Finished at 170 seconds\n"
     ]
    }
   ],
   "source": [
    "running_funtion_complete(run_train_model,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'COMPLETED', 'outputs': {}, 'results': {}, 'k8s': {'pods': [{'metadata': {'creationTimestamp': 1720708233.0, 'generateName': 'j-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97-', 'labels': {'app.kubernetes.io/instance': 'dhcore-359b0479-9089-4c99-a26f-0e4dae5cef97', 'app.kubernetes.io/managed-by': 'dhcore', 'app.kubernetes.io/part-of': 'dhcore-mlparksrem', 'app.kubernetes.io/version': '359b0479-9089-4c99-a26f-0e4dae5cef97', 'batch.kubernetes.io/controller-uid': '94bb8ac6-af64-4e1c-b9c7-c7b3209a4889', 'batch.kubernetes.io/job-name': 'j-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97', 'controller-uid': '94bb8ac6-af64-4e1c-b9c7-c7b3209a4889', 'job-name': 'j-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}, 'managedFields': [{'apiVersion': 'v1', 'fieldsType': 'FieldsV1', 'manager': 'kube-controller-manager', 'operation': 'Update', 'time': 1720708233.0}, {'apiVersion': 'v1', 'fieldsType': 'FieldsV1', 'manager': 'kubelet', 'operation': 'Update', 'subresource': 'status', 'time': 1720708388.0}], 'name': 'j-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97-kbnvg', 'namespace': 'digitalhub-tenant1', 'ownerReferences': [{'apiVersion': 'batch/v1', 'blockOwnerDeletion': True, 'controller': True, 'kind': 'Job', 'name': 'j-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97', 'uid': '94bb8ac6-af64-4e1c-b9c7-c7b3209a4889'}], 'resourceVersion': '414845', 'uid': 'da8c155a-257d-4844-8baf-8ee1e4406f05'}, 'spec': {'containers': [{'args': ['--config', '/shared/function.yaml'], 'command': ['/usr/local/bin/processor'], 'env': [{'name': 'DH_RUN_SECRET_NAME', 'value': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}, {'name': 'PYTHONPATH', 'value': '${PYTHONPATH}:/shared/'}, {'name': 'DIGITALHUB_CORE_TOKEN', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_TOKEN', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}, {'name': 'DIGITALHUB_CORE_AUTH_SUB', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_AUTH_SUB', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}, {'name': 'PROJECT_NAME', 'value': 'MLparksrem'}, {'name': 'RUN_ID', 'value': '359b0479-9089-4c99-a26f-0e4dae5cef97'}, {'name': 'DIGITALHUB_CORE_USER', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_USER', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}], 'envFrom': [{'configMapRef': {'name': 'digitalhub-common-env'}}, {'secretRef': {'name': 'digitalhub-common-creds'}}], 'image': 'registry.tenant1.digitalhub-dev.smartcommunitylab.it/dhcore-mlparksrem-training_model-143bc:143bcbb9-1f8d-4d7c-89ae-567343111138', 'imagePullPolicy': 'IfNotPresent', 'name': 'c-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97', 'terminationMessagePath': '/dev/termination-log', 'terminationMessagePolicy': 'File', 'volumeMounts': [{'mountPath': '/shared', 'name': 'shared-dir'}, {'mountPath': '/init-config-map', 'name': 'init-config-map'}, {'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount', 'name': 'kube-api-access-ch7bk', 'readOnly': True}]}], 'dnsPolicy': 'ClusterFirst', 'enableServiceLinks': True, 'imagePullSecrets': [{'name': 'registry-credentials'}], 'initContainers': [{'command': ['/bin/bash', '-c', '/app/builder-tool.sh'], 'env': [{'name': 'DH_RUN_SECRET_NAME', 'value': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}, {'name': 'PYTHONPATH', 'value': '${PYTHONPATH}:/shared/'}, {'name': 'DIGITALHUB_CORE_TOKEN', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_TOKEN', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}, {'name': 'DIGITALHUB_CORE_AUTH_SUB', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_AUTH_SUB', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}, {'name': 'PROJECT_NAME', 'value': 'MLparksrem'}, {'name': 'RUN_ID', 'value': '359b0479-9089-4c99-a26f-0e4dae5cef97'}, {'name': 'DIGITALHUB_CORE_USER', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_USER', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}], 'envFrom': [{'configMapRef': {'name': 'digitalhub-common-env'}}, {'secretRef': {'name': 'digitalhub-common-creds'}}], 'image': 'ghcr.io/scc-digitalhub/digitalhub-core-builder-tool:latest', 'imagePullPolicy': 'Always', 'name': 'init-container-359b0479-9089-4c99-a26f-0e4dae5cef97', 'terminationMessagePath': '/dev/termination-log', 'terminationMessagePolicy': 'File', 'volumeMounts': [{'mountPath': '/shared', 'name': 'shared-dir'}, {'mountPath': '/init-config-map', 'name': 'init-config-map'}, {'mountPath': '/var/run/secrets/kubernetes.io/serviceaccount', 'name': 'kube-api-access-ch7bk', 'readOnly': True}]}], 'nodeName': 'digitalhub-dev-md-0-9ssk4-gpnw2', 'preemptionPolicy': 'PreemptLowerPriority', 'priority': 0, 'restartPolicy': 'Never', 'schedulerName': 'default-scheduler', 'serviceAccount': 'default', 'serviceAccountName': 'default', 'terminationGracePeriodSeconds': 30, 'tolerations': [{'effect': 'NoExecute', 'key': 'node.kubernetes.io/not-ready', 'operator': 'Exists', 'tolerationSeconds': 300}, {'effect': 'NoExecute', 'key': 'node.kubernetes.io/unreachable', 'operator': 'Exists', 'tolerationSeconds': 300}], 'volumes': [{'emptyDir': {'sizeLimit': {'number': 104857600, 'format': 'BINARY_SI'}}, 'name': 'shared-dir'}, {'configMap': {'defaultMode': 420, 'name': 'init-config-map-359b0479-9089-4c99-a26f-0e4dae5cef97'}, 'name': 'init-config-map'}, {'name': 'kube-api-access-ch7bk', 'projected': {'defaultMode': 420, 'sources': [{'serviceAccountToken': {'expirationSeconds': 3607, 'path': 'token'}}, {'configMap': {'items': [{'key': 'ca.crt', 'path': 'ca.crt'}], 'name': 'kube-root-ca.crt'}}, {'downwardAPI': {'items': [{'fieldRef': {'apiVersion': 'v1', 'fieldPath': 'metadata.namespace'}, 'path': 'namespace'}]}}]}}]}, 'status': {'conditions': [{'lastTransitionTime': 1720708387.0, 'status': 'False', 'type': 'PodReadyToStartContainers'}, {'lastTransitionTime': 1720708234.0, 'reason': 'PodCompleted', 'status': 'True', 'type': 'Initialized'}, {'lastTransitionTime': 1720708386.0, 'reason': 'PodCompleted', 'status': 'False', 'type': 'Ready'}, {'lastTransitionTime': 1720708386.0, 'reason': 'PodCompleted', 'status': 'False', 'type': 'ContainersReady'}, {'lastTransitionTime': 1720708233.0, 'status': 'True', 'type': 'PodScheduled'}], 'containerStatuses': [{'containerID': 'containerd://6da506bba0b24b76cd045c770b1b9cf5ef472da883f94988cd4417eca3e57277', 'image': 'registry.tenant1.digitalhub-dev.smartcommunitylab.it/dhcore-mlparksrem-training_model-143bc:143bcbb9-1f8d-4d7c-89ae-567343111138', 'imageID': 'registry.tenant1.digitalhub-dev.smartcommunitylab.it/dhcore-mlparksrem-training_model-143bc@sha256:388c0b82e1ff82747d220f187bdaa80e81bd3c7eafed5a80f7d9ff9a33ff7074', 'name': 'c-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97', 'ready': False, 'restartCount': 0, 'started': False, 'state': {'terminated': {'containerID': 'containerd://6da506bba0b24b76cd045c770b1b9cf5ef472da883f94988cd4417eca3e57277', 'exitCode': 0, 'finishedAt': 1720708386.0, 'reason': 'Completed', 'startedAt': 1720708354.0}}}], 'hostIP': '10.1.0.6', 'hostIPs': [{'ip': '10.1.0.6'}], 'initContainerStatuses': [{'containerID': 'containerd://4505b525d170e65b612eeb9b37507deffbf5befcc858b7cb7ef19cc888a37a6c', 'image': 'ghcr.io/scc-digitalhub/digitalhub-core-builder-tool:latest', 'imageID': 'ghcr.io/scc-digitalhub/digitalhub-core-builder-tool@sha256:bbc06eee8fc253863d0cd10286e1914c688988588838a45a4ca732222765e72e', 'name': 'init-container-359b0479-9089-4c99-a26f-0e4dae5cef97', 'ready': True, 'restartCount': 0, 'started': False, 'state': {'terminated': {'containerID': 'containerd://4505b525d170e65b612eeb9b37507deffbf5befcc858b7cb7ef19cc888a37a6c', 'exitCode': 0, 'finishedAt': 1720708234.0, 'reason': 'Completed', 'startedAt': 1720708234.0}}}], 'phase': 'Succeeded', 'podIP': '192.168.2.175', 'podIPs': [{'ip': '192.168.2.175'}], 'qosClass': 'BestEffort', 'startTime': 1720708233.0}}], 'job': {'metadata': {'creationTimestamp': 1720708233.0, 'generation': 1, 'labels': {'app.kubernetes.io/instance': 'dhcore-359b0479-9089-4c99-a26f-0e4dae5cef97', 'app.kubernetes.io/managed-by': 'dhcore', 'app.kubernetes.io/part-of': 'dhcore-mlparksrem', 'app.kubernetes.io/version': '359b0479-9089-4c99-a26f-0e4dae5cef97'}, 'managedFields': [{'apiVersion': 'batch/v1', 'fieldsType': 'FieldsV1', 'manager': 'Kubernetes Java Client', 'operation': 'Update', 'time': 1720708233.0}, {'apiVersion': 'batch/v1', 'fieldsType': 'FieldsV1', 'manager': 'kube-controller-manager', 'operation': 'Update', 'subresource': 'status', 'time': 1720708388.0}], 'name': 'j-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97', 'namespace': 'digitalhub-tenant1', 'resourceVersion': '414846', 'uid': '94bb8ac6-af64-4e1c-b9c7-c7b3209a4889'}, 'apiVersion': 'batch/v1', 'kind': 'Job', 'spec': {'activeDeadlineSeconds': 259200, 'backoffLimit': 0, 'completionMode': 'NonIndexed', 'completions': 1, 'manualSelector': False, 'parallelism': 1, 'podReplacementPolicy': 'TerminatingOrFailed', 'selector': {'matchLabels': {'batch.kubernetes.io/controller-uid': '94bb8ac6-af64-4e1c-b9c7-c7b3209a4889'}}, 'suspend': False, 'template': {'metadata': {'labels': {'app.kubernetes.io/instance': 'dhcore-359b0479-9089-4c99-a26f-0e4dae5cef97', 'app.kubernetes.io/managed-by': 'dhcore', 'app.kubernetes.io/part-of': 'dhcore-mlparksrem', 'app.kubernetes.io/version': '359b0479-9089-4c99-a26f-0e4dae5cef97', 'batch.kubernetes.io/controller-uid': '94bb8ac6-af64-4e1c-b9c7-c7b3209a4889', 'batch.kubernetes.io/job-name': 'j-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97', 'controller-uid': '94bb8ac6-af64-4e1c-b9c7-c7b3209a4889', 'job-name': 'j-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}, 'name': 'j-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}, 'spec': {'containers': [{'args': ['--config', '/shared/function.yaml'], 'command': ['/usr/local/bin/processor'], 'env': [{'name': 'DH_RUN_SECRET_NAME', 'value': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}, {'name': 'PYTHONPATH', 'value': '${PYTHONPATH}:/shared/'}, {'name': 'DIGITALHUB_CORE_TOKEN', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_TOKEN', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}, {'name': 'DIGITALHUB_CORE_AUTH_SUB', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_AUTH_SUB', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}, {'name': 'PROJECT_NAME', 'value': 'MLparksrem'}, {'name': 'RUN_ID', 'value': '359b0479-9089-4c99-a26f-0e4dae5cef97'}, {'name': 'DIGITALHUB_CORE_USER', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_USER', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}], 'envFrom': [{'configMapRef': {'name': 'digitalhub-common-env'}}, {'secretRef': {'name': 'digitalhub-common-creds'}}], 'image': 'registry.tenant1.digitalhub-dev.smartcommunitylab.it/dhcore-mlparksrem-training_model-143bc:143bcbb9-1f8d-4d7c-89ae-567343111138', 'imagePullPolicy': 'IfNotPresent', 'name': 'c-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97', 'terminationMessagePath': '/dev/termination-log', 'terminationMessagePolicy': 'File', 'volumeMounts': [{'mountPath': '/shared', 'name': 'shared-dir'}, {'mountPath': '/init-config-map', 'name': 'init-config-map'}]}], 'dnsPolicy': 'ClusterFirst', 'imagePullSecrets': [{'name': 'registry-credentials'}], 'initContainers': [{'command': ['/bin/bash', '-c', '/app/builder-tool.sh'], 'env': [{'name': 'DH_RUN_SECRET_NAME', 'value': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}, {'name': 'PYTHONPATH', 'value': '${PYTHONPATH}:/shared/'}, {'name': 'DIGITALHUB_CORE_TOKEN', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_TOKEN', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}, {'name': 'DIGITALHUB_CORE_AUTH_SUB', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_AUTH_SUB', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}, {'name': 'PROJECT_NAME', 'value': 'MLparksrem'}, {'name': 'RUN_ID', 'value': '359b0479-9089-4c99-a26f-0e4dae5cef97'}, {'name': 'DIGITALHUB_CORE_USER', 'valueFrom': {'secretKeyRef': {'key': 'DIGITALHUB_CORE_USER', 'name': 'sec-python-python-job-359b0479-9089-4c99-a26f-0e4dae5cef97'}}}], 'envFrom': [{'configMapRef': {'name': 'digitalhub-common-env'}}, {'secretRef': {'name': 'digitalhub-common-creds'}}], 'image': 'ghcr.io/scc-digitalhub/digitalhub-core-builder-tool:latest', 'imagePullPolicy': 'Always', 'name': 'init-container-359b0479-9089-4c99-a26f-0e4dae5cef97', 'terminationMessagePath': '/dev/termination-log', 'terminationMessagePolicy': 'File', 'volumeMounts': [{'mountPath': '/shared', 'name': 'shared-dir'}, {'mountPath': '/init-config-map', 'name': 'init-config-map'}]}], 'restartPolicy': 'Never', 'schedulerName': 'default-scheduler', 'terminationGracePeriodSeconds': 30, 'volumes': [{'emptyDir': {'sizeLimit': {'number': 104857600, 'format': 'BINARY_SI'}}, 'name': 'shared-dir'}, {'configMap': {'defaultMode': 420, 'name': 'init-config-map-359b0479-9089-4c99-a26f-0e4dae5cef97'}, 'name': 'init-config-map'}]}}}, 'status': {'completionTime': 1720708388.0, 'conditions': [{'lastProbeTime': 1720708388.0, 'lastTransitionTime': 1720708388.0, 'status': 'True', 'type': 'Complete'}], 'ready': 0, 'startTime': 1720708233.0, 'succeeded': 1, 'terminating': 0}}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_train_model.refresh()\n",
    "run_train_model.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting serve_multimodel.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"serve_multimodel.py\"\n",
    "\n",
    "from darts.models import NBEATSModel\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def init_function(context):\n",
    "\n",
    "    # Qua ti setti l'id del modello che vuoi caricare\n",
    "    model_id = \"8be239dc-8798-48ff-bc3b-80d1d80cc2af\"\n",
    "\n",
    "    # prendi l'entity model sulla base dell'id\n",
    "    model = context.project.get_model(entity_id=model_id)\n",
    "    path = model.download()\n",
    "    local_path_model = \"extracted_model/\"\n",
    "    # Qua fai unzip immagino\n",
    "    with ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(local_path_model)\n",
    "    \n",
    "    # codice che carica il modello\n",
    "    input_chunk_length = 24\n",
    "    output_chunk_length = 12\n",
    "    name_model_local = local_path_model +\"parcheggi_predictor_model.pt\"\n",
    "    mm = NBEATSModel(\n",
    "            input_chunk_length,\n",
    "            output_chunk_length\n",
    "    ).load(name_model_local)\n",
    "\n",
    "    # settare model nel context di nuclio (non su project che è il context nostro)\n",
    "    context.setattr(\"model\", mm)\n",
    "\n",
    "def serve(context, event):\n",
    "\n",
    "    # Sostanzialmente invochiamo la funzione con una chiamata REST\n",
    "    # Nel body della richiesta mandi l'inference input\n",
    "    \n",
    "    if isinstance(event.body, bytes):\n",
    "        body = json.loads(event.body)\n",
    "    context.logger.info(f\"Received event: {body}\")\n",
    "    inference_input = body[\"inference_input\"]\n",
    "    \n",
    "    return context.model.predict(n=output_chunk_length*2,\n",
    "                                 series=inference_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"serve_model\"\n",
    "func = ml_proj.new_function(name=FUNCTION_NAME,\n",
    "                            kind=\"python\",\n",
    "                            python_version=\"PYTHON3_9\",\n",
    "                            source={\n",
    "                                 \"source\": \"serve_multimodel.py\",\n",
    "                                 \"handler\": \"serve\",\n",
    "                                 \"init_function\": \"init\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_serve_model = func.run(action=\"serve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds: 0, status: READY ...\n",
      "Seconds: 10, status: READY ...\n",
      "Seconds: 20, status: RUNNING ...\n"
     ]
    }
   ],
   "source": [
    "running_funtion_complete(run_serve_model,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digitalhub-core",
   "language": "python",
   "name": "digitalhub-core"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
