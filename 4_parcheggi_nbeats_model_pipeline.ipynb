{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a563fb50-1483-4eb3-a140-8e7ad24c2a85",
   "metadata": {},
   "source": [
    "# Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0cc1de-0172-4def-9bf2-40f25c3bfe25",
   "metadata": {},
   "source": [
    "In this step we will create Monitor workflow pipeline based on schedule, whose purpose is to call\n",
    "\n",
    "1) call the service created after training a data prediction model using darts framework and NBEATS Deep Learning model. (see notebook parcheggi_ml.ipynb)\n",
    "2) save the prediction in database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96edd9-21a1-4460-9769-0c98ce27b7fa",
   "metadata": {},
   "source": [
    "## Platform Support - Data Ops\n",
    "We use the platform support to read the data created into the platform after the execution of notebook(parcheggi_data_pipeline.ipynb) for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ea73c54-438f-4aab-8f2b-a0f6efd5e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import digitalhub as dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a631269-98e6-481d-ae39-06aebc668617",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://opendata.comune.bologna.it/api/explore/v2.1/catalog/datasets/disponibilita-parcheggi-storico/exports/csv?lang=it&timezone=UTC&use_labels=true&delimiter=%3B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d1aee01-269c-49ca-a6b1-a2234d88861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created project parcheggi-scheduler\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'parcheggi-scheduler'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_NAME = \"parcheggi-scheduler\"\n",
    "proj = dh.get_or_create_project(PROJECT_NAME)\n",
    "print(\"created project {}\".format(PROJECT_NAME))\n",
    "PROJECT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4f802ae-ef0b-4e9a-b605-c069f9dc110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_download = proj.get_dataitem(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c35b01b-b15d-47d1-bd78-1c650c78f9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcheggio</th>\n",
       "      <th>data</th>\n",
       "      <th>posti_liberi</th>\n",
       "      <th>posti_occupati</th>\n",
       "      <th>posti_totali</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-06-07T01:59:00+00:00</td>\n",
       "      <td>484.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>2024-06-07T02:09:00+00:00</td>\n",
       "      <td>369.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>470</td>\n",
       "      <td>44.501153</td>\n",
       "      <td>11.336062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>2024-06-07T02:19:00+00:00</td>\n",
       "      <td>369.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>470</td>\n",
       "      <td>44.501153</td>\n",
       "      <td>11.336062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-06-07T02:29:00+00:00</td>\n",
       "      <td>487.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>2024-06-07T02:29:00+00:00</td>\n",
       "      <td>369.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>470</td>\n",
       "      <td>44.501153</td>\n",
       "      <td>11.336062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53399</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-10-17T10:49:00+00:00</td>\n",
       "      <td>152.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53400</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-10-17T11:09:00+00:00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53401</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>2024-10-17T11:09:00+00:00</td>\n",
       "      <td>249.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>470</td>\n",
       "      <td>44.501153</td>\n",
       "      <td>11.336062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53402</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-10-17T11:19:00+00:00</td>\n",
       "      <td>69.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53403</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-10-17T11:29:00+00:00</td>\n",
       "      <td>142.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53404 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         parcheggio                       data  posti_liberi  posti_occupati  \\\n",
       "0       VIII Agosto  2024-06-07T01:59:00+00:00         484.0           141.0   \n",
       "1         Riva Reno  2024-06-07T02:09:00+00:00         369.0           101.0   \n",
       "2         Riva Reno  2024-06-07T02:19:00+00:00         369.0           101.0   \n",
       "3       VIII Agosto  2024-06-07T02:29:00+00:00         487.0           138.0   \n",
       "4         Riva Reno  2024-06-07T02:29:00+00:00         369.0           101.0   \n",
       "...             ...                        ...           ...             ...   \n",
       "53399  Autostazione  2024-10-17T10:49:00+00:00         152.0           113.0   \n",
       "53400   VIII Agosto  2024-10-17T11:09:00+00:00          84.0           541.0   \n",
       "53401     Riva Reno  2024-10-17T11:09:00+00:00         249.0           221.0   \n",
       "53402   VIII Agosto  2024-10-17T11:19:00+00:00          69.0           556.0   \n",
       "53403  Autostazione  2024-10-17T11:29:00+00:00         142.0           123.0   \n",
       "\n",
       "       posti_totali        lat        lon  \n",
       "0               625  44.500297  11.345368  \n",
       "1               470  44.501153  11.336062  \n",
       "2               470  44.501153  11.336062  \n",
       "3               625  44.500297  11.345368  \n",
       "4               470  44.501153  11.336062  \n",
       "...             ...        ...        ...  \n",
       "53399           265  44.504422  11.346514  \n",
       "53400           625  44.500297  11.345368  \n",
       "53401           470  44.501153  11.336062  \n",
       "53402           625  44.500297  11.345368  \n",
       "53403           265  44.504422  11.346514  \n",
       "\n",
       "[53404 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkings_df = data_item_download.as_df()\n",
    "parkings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7fc41a-59b4-4430-81fe-48b693495d60",
   "metadata": {},
   "source": [
    "In this script, one needs to update the 'serve' RUN id of the model service. From the project console, go to RUNS(model_serve) in RUNNING state, and copy the identifier value (last part of key value) \n",
    "\n",
    "**project.get_run(identifier='f4823893-1785-4a14-aeb3-99335b64f0fb')**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "391e515b-347d-4ab0-9a9f-5c3b509087b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/predict_nbeats_timeseries.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/predict_nbeats_timeseries.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import datetime \n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import digitalhub as dh\n",
    "\n",
    "@handler()\n",
    "def predict_day(project,  parkings_di):\n",
    "    \"\"\"\n",
    "    Monitor and predict parking occupancy.\n",
    "    \"\"\"\n",
    "\n",
    "    # get serving predictor function run\n",
    "    run_serve_model =  project.get_run(identifier='3ac40967-cda1-43b4-bae4-c7401f7e845d')\n",
    "    \n",
    "    # get current date and time as string\n",
    "    date_str = datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "    # get parkings dataset and convert it to a dataframe\n",
    "    parkings_df = parkings_di.as_df()\n",
    "\n",
    "    # initialize an empty dataframe for predictions\n",
    "    pred_df = pd.DataFrame(columns=['parcheggio', 'datetime', 'predicted_mean'])\n",
    "\n",
    "    # iterate over each parking in the dataset\n",
    "    parcheggi =  parkings_df['parcheggio'].unique()\n",
    "    #parcheggi = ['Riva Reno' ,'VIII Agosto']\n",
    "    for parking_str in parcheggi:\n",
    "        # construct API URL based on parking and current date\n",
    "        API_URL = f'https://opendata.comune.bologna.it/api/explore/v2.1/catalog/datasets/disponibilita-parcheggi-storico/records?where=data%3C%3D%27{date_str}%27%20and%20parcheggio%3D%27{parking_str}%27&order_by=data%20DESC&limit=100'\n",
    "\n",
    "        # define the file to store the latest data\n",
    "        latest_data_file = 'last_records.json'\n",
    "\n",
    "        # fetch data from the API and save it to a file\n",
    "        with requests.get(API_URL) as r:\n",
    "            with open(latest_data_file, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "\n",
    "        # read the latest data from the file and process it\n",
    "        with open(latest_data_file) as f:\n",
    "            json_data = json.load(f)\n",
    "            df_latest = pd.json_normalize(json_data['results']).drop(columns=['guid', 'occupazione']).rename(columns={\"coordinate.lon\": \"lon\", \"coordinate.lat\": \"lat\"})\n",
    "            df_latest.data = df_latest.data.astype('datetime64[ns, UTC]')\n",
    "            df_latest['value'] = df_latest.posti_occupati / df_latest.posti_totali\n",
    "            df_latest['date'] = df_latest.data.dt.round('30min')\n",
    "            df_latest = df_latest.drop(columns=['parcheggio'])\n",
    "            df_latest = df_latest.groupby('date').agg({'value': 'mean'})\n",
    "\n",
    "        # convert the processed data to JSON and make a request to the serving predictor function\n",
    "        jsonstr = df_latest.reset_index().to_json(orient='records')\n",
    "        arr = json.loads(jsonstr)\n",
    "        SERVICE_URL = run_serve_model.status.to_dict()[\"service\"][\"url\"]\n",
    "        with requests.post(f'http://{SERVICE_URL}', json={\"inference_input\":arr}) as r:\n",
    "            res = json.loads(r.content)\n",
    "        res_df = pd.DataFrame(res)\n",
    "        res_df['datetime'] = res_df['date']\n",
    "        res_df['parcheggio'] = parking_str\n",
    "        res_df['predicted_mean'] = res_df['value']\n",
    "        res_df = res_df.drop(columns=['date', 'value'])\n",
    "        pred_df = pd.concat([pred_df, res_df], ignore_index=True)\n",
    "\n",
    "    # concatenate the predicted results with the existing data (if any) and remove duplicates\n",
    "    old_pd = pred_df\n",
    "    try: \n",
    "        dat_old = project.get_dataitem('parking_prediction_nbeats_model')\n",
    "        old_pd = pd.concat([dat_old.as_df(), pred_df], ignore_index=True)\n",
    "        old_pd = old_pd.drop_duplicates(subset=['parcheggio', 'datetime'])\n",
    "    except: pass\n",
    "\n",
    "    # log the predictions as a dataset in the project\n",
    "    project.log_dataitem('parking_prediction_nbeats_model', data=old_pd, kind=\"table\")\n",
    "\n",
    "    old_pd = pred_df.copy()\n",
    "    old_pd['slice_datetime'] = date_str\n",
    "    try:\n",
    "        dat_old = project.get_dataitem('parking_prediction_nbeats_model_sliced')\n",
    "        old_pd = pd.concat([dat_old.as_df(), old_pd], ignore_index=True)\n",
    "    except: pass\n",
    "\n",
    "    # log the predictions as a dataset in the project\n",
    "    project.log_dataitem('parking_prediction_nbeats_model_sliced', data=old_pd, kind=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fdbf3dae-a96e-4816-99da-f04dd69f60cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = proj.new_function(name=\"predict-day-nbeats-model\",\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_10\",\n",
    "                         source={\"source\": \"src/predict_nbeats_timeseries.py\", \"handler\": \"predict_day\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1013317b-cc27-4e3f-b0fd-62007689082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_download = proj.get_dataitem(\"dataset\").key\n",
    "run_monitor_parkings = func.run(action=\"job\",inputs={\"parkings_di\": data_item_download},outputs={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54451d-e5d4-4f33-bb9a-0e10b7bdd171",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038cdb6-790c-4b9c-85d0-c16bce600dd9",
   "metadata": {},
   "source": [
    "In this step we will create a workflow pipeline whose purpose is to call the download function to fetch data and pass it to predict_day function which produce prediction based on NBEATS model. The entire workflow is scheduled for frequent runs based on frequrency provided using CRON expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55b12490-b25b-4c76-8d5e-6b5ceaf28289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/parkings_pipeline_nbeats_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/parkings_pipeline_nbeats_model.py\"\n",
    "\n",
    "from digitalhub_runtime_kfp.dsl import pipeline_context\n",
    "\n",
    "def myhandler(di):\n",
    "    with pipeline_context() as pc:\n",
    "        s2_predict = pc.step(name=\"predict-day-nbeats-model\", function=\"predict-day-nbeats-model\", action=\"job\", inputs={\"parkings_di\":di}, outputs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9478efdc-6051-4e2e-abe1-691781f6fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = proj.new_workflow(name=\"pipeline_parcheggi_nbeats_model\", kind=\"kfp\", source={\"source\": \"src/parkings_pipeline_nbeats_model.py\", \"handler\": \"myhandler\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695936ab-2f87-46c4-8b56-3e1505abe428",
   "metadata": {},
   "source": [
    "## Schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf15f97-d989-45de-bb13-e6988a685045",
   "metadata": {},
   "source": [
    "Nbeats model Pipeline workflow is scheduled for frequent runs using Crons expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3aa5d731-4eff-4750-b6c9-883c017e8795",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = proj.get_dataitem(\"dataset\").key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9009d80b-0180-4807-9261-09b4e40f5944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'kfp+run', 'metadata': {'project': 'parcheggi-scheduler', 'name': '91beb6c6-bf31-40db-a1af-e734ee5e51bb', 'created': '2024-10-17T09:44:41.044Z', 'updated': '2024-10-17T09:44:41.061Z', 'created_by': 'khurshid@fbk.eu', 'updated_by': 'khurshid@fbk.eu'}, 'spec': {'task': 'kfp+pipeline://parcheggi-scheduler/pipeline_parcheggi_nbeats_model:62cedcfe-3956-4a79-b314-95d113501f29', 'local_execution': False, 'function': 'kfp://parcheggi-scheduler/pipeline_parcheggi_nbeats_model:62cedcfe-3956-4a79-b314-95d113501f29', 'source': {'source': 'src/parkings_pipeline_nbeats_model.py', 'handler': 'myhandler', 'base64': 'CmZyb20gZGlnaXRhbGh1Yl9ydW50aW1lX2tmcC5kc2wgaW1wb3J0IHBpcGVsaW5lX2NvbnRleHQKCmRlZiBteWhhbmRsZXIoZGkpOgogICAgd2l0aCBwaXBlbGluZV9jb250ZXh0KCkgYXMgcGM6CiAgICAgICAgczJfcHJlZGljdCA9IHBjLnN0ZXAobmFtZT0icHJlZGljdC1kYXktbmJlYXRzLW1vZGVsIiwgZnVuY3Rpb249InByZWRpY3QtZGF5LW5iZWF0cy1tb2RlbCIsIGFjdGlvbj0iam9iIiwgaW5wdXRzPXsicGFya2luZ3NfZGkiOmRpfSwgb3V0cHV0cz17fSkK', 'lang': 'python'}, 'schedule': '*/55 * * * *', 'inputs': {}, 'outputs': {}, 'parameters': {'di': 'store://parcheggi-scheduler/dataitem/table/dataset:bb63bfa4-7144-46bf-bcb5-5f494cbd9bc0'}}, 'status': {'state': 'READY', 'transitions': [{'status': 'READY', 'time': '2024-10-17T09:44:41.061078163Z'}, {'status': 'BUILT', 'time': '2024-10-17T09:44:41.050416849Z'}]}, 'user': 'khurshid@fbk.eu', 'project': 'parcheggi-scheduler', 'id': '91beb6c6-bf31-40db-a1af-e734ee5e51bb', 'key': 'store://parcheggi-scheduler/run/kfp+run/91beb6c6-bf31-40db-a1af-e734ee5e51bb'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.run(parameters={\"di\": di}, schedule=\"*/55 * * * *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed929825-462e-4f59-8a4d-05a694bf6f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
