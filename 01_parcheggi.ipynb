{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6cab4-a33e-4682-8629-083e483b68fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45de8d1-7d61-4a41-8545-a506b6b66419",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "\n",
    "### 1.1. Download data\n",
    "Download data from the API, and load it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0aff8-754a-4cab-93d6-a934528477e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://opendata.comune.bologna.it/api/explore/v2.1/catalog/datasets/disponibilita-parcheggi-storico/exports/csv?lang=it&timezone=UTC&use_labels=true&delimiter=%3B\"\n",
    "\n",
    "df = pd.read_csv(URL, sep=\";\")\n",
    "df[['lat', 'lon']] = df['coordinate'].str.split(', ',expand=True)\n",
    "df = df.drop(columns=['% occupazione', 'GUID', 'coordinate']).rename(columns={'Parcheggio': 'parcheggio', 'Data': 'data', 'Posti liberi': 'posti_liberi', 'Posti occupati': 'posti_occupati', 'Posti totali': 'posti_totali'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3aa2d0-6b0c-4123-b038-ffe4a07978e1",
   "metadata": {},
   "source": [
    "### 1.2. Extract parkings\n",
    "Extract distinct parkings from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867cb24-0b93-4be4-8e68-bd20de3e87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = ['parcheggio', 'lat', 'lon']\n",
    "df_parcheggi = df.groupby(['parcheggio']).first().reset_index()[KEYS]\n",
    "df_parcheggi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98ade66-8898-4da7-9c0b-d1526356f0e3",
   "metadata": {},
   "source": [
    "### 1.3 Aggregate Parking Data\n",
    "Aggregate Parking Data by date, hour, dow, and parking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08adc1-0597-4296-8ab0-62bcc3190cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = df.copy()\n",
    "rdf['data'] = pd.to_datetime(rdf['data'])\n",
    "rdf['day'] = rdf['data'].apply(lambda t: t.replace(second=0, minute=0))\n",
    "rdf['lat'] = rdf['lat'].apply(lambda t: float(t))\n",
    "rdf['lon'] = rdf['lon'].apply(lambda t: float(t))\n",
    "rdf = rdf.drop(columns=['data'])\n",
    "grouped =rdf.groupby(['parcheggio','day']).mean()\n",
    "df_aggregated = grouped.reset_index()\n",
    "df_aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ef504b-dd2a-4bca-9a19-b4ff881de136",
   "metadata": {},
   "source": [
    "## 2. Platform Support - Data Ops\n",
    "\n",
    "We use the platform support to load the data into the platform, version it, and automate the execution of the data management operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b168e-4679-4356-b75a-bfa2daa6948a",
   "metadata": {},
   "source": [
    "### 2.0. Initalization\n",
    "Create the working context: data management project for the parking data processing. Project is a placeholder for the code, data, and management of the parking data operations. To keep it reproducible, we use the `git` source type to store the definition and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26d885-e162-4a88-bb53-028ac33ee401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "import getpass as gt\n",
    "\n",
    "PROJECT_NAME = \"parcheggi-\"+gt.getuser()\n",
    "proj = dh.get_or_create_project(PROJECT_NAME)\n",
    "print(\"created project {}\".format(PROJECT_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd353f3-2eb5-4ef0-b7c2-48302c70c117",
   "metadata": {},
   "source": [
    "## 2.1 Load source data\n",
    "We can load the local data into the platform by creating a dataitem from the local (in-memory) dataframe, or from a local or remote file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03505eb5-9f31-4d6e-9cec-819ea1cce44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_key = proj.new_dataitem(name=\"source_data\", kind=\"table\").write_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ade11-5238-4d86-9b4b-67871d7c4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db24ca7-408c-4356-8d2a-624464655c84",
   "metadata": {},
   "source": [
    "A dataitem is a resource which stores a \"dataset\" with a set of properties and abstracts away the complexity of reading and writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e400c-28a2-4e76-8eec-e85f4ceee78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = proj.get_dataitem(\"source_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af2c43-3246-4b8e-8cdd-15a71a714a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498aa9a2-6fef-48e0-bcaa-3b83a7187d1d",
   "metadata": {},
   "source": [
    "We can read back as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a394f-45a2-4eb5-a1c3-8c997e27dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_df = source_data.as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93386b3-adda-4a4e-852a-3309dceb14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f95339-10a5-492a-9240-90f93a71cd91",
   "metadata": {},
   "source": [
    "### Exercise: dataitems\n",
    "Create a dataitem from a remote source and load as dataframe:\n",
    "Suggestion: new_dataitem accepts urls as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c03a1-d0cb-4638-877d-ca4b7faffa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOTE_URL=\"https://raw.githubusercontent.com/datasets/world-cities/master/data/world-cities.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b32236-7cfb-4c23-bedc-48a6c4fe8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_di = proj.new_dataitem(name=\"world_cities\", kind=\"table\", path=REMOTE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4ddc2-d986-40d6-89ab-77e61e906989",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb0521-0ae2-44f2-9d37-8576695d597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_df = cities_di.as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a536aa92-281d-4950-bc61-4549f16fb0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59842a77-4eb2-4165-8e4d-8283f975525a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4faeb9db-cbbd-4928-86e5-4cb596a8699d",
   "metadata": {},
   "source": [
    "### 2.2. Data management functions\n",
    "We convert the data management ETL operations into functions - single executable operations that can be executed in the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e19aaf-9c96-43fb-8265-648c138f431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"download_all.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"dataset\"])\n",
    "def downloader(project, url):\n",
    "    df = url.as_df(file_format='csv',sep=\";\")\n",
    "    df[['lat', 'lon']] = df['coordinate'].str.split(', ',expand=True)\n",
    "    df = df.drop(columns=['% occupazione', 'GUID', 'coordinate']).rename(columns={'Parcheggio': 'parcheggio', 'Data': 'data', 'Posti liberi': 'posti_liberi', 'Posti occupati': 'posti_occupati', 'Posti totali': 'posti_totali'})\n",
    "    df[\"lat\"] = pd.to_numeric(df[\"lat\"])\n",
    "    df[\"lon\"] = pd.to_numeric(df[\"lon\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf51844-ecad-46f7-a304-5cf87f4e808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = proj.new_function(name=\"downloader-funct\",\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"download_all.py\", \"handler\": \"downloader\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d21a2-6c80-427c-a0c2-1dd30e006b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = proj.new_dataitem(name=\"url_data_item\",kind=\"table\",path=URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c17467-8fc7-4813-8a9e-aa30258c469b",
   "metadata": {},
   "source": [
    "### Local execution\n",
    "We can execute the function code locally in the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0199b00-00ef-4851-a014-02e38574c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_local = func.run(action=\"job\",inputs={\"url\":di.key},outputs={\"dataset\":\"dataset\"}, local_execution=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c3db1-5095-4a00-818c-0b040f3e720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_local.status.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247430ab-ef99-4749-ac97-8228ce66d2bd",
   "metadata": {},
   "source": [
    "The results are stored in the platform and are ready to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e84c9-4dda-4eb3-a4be-0276f5209e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_local_dataset=proj.get_dataitem(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa96d9-aead-44f9-9ae5-ce3f0a76d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_local_dataset.metadata.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee255a-132a-468c-baff-6a69b40ba3ff",
   "metadata": {},
   "source": [
    "The sdk has extracted the schema for the table automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ec40c-9fe8-46d1-9205-de5e6de07cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pd.DataFrame.from_records(run_download_local_dataset.spec.schema['fields'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ef546-37b6-464d-b69a-27b416c101a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b9cd49-4632-4b5c-bf9b-6bec887885bb",
   "metadata": {},
   "source": [
    "It also builds a preview of the actual content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07a233-0464-4eb2-942c-2baf025d777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = dict((e['name'],e['value']) for e in run_download_local_dataset.status.preview['cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bdf957-cffd-49cd-adce-8285c97fb072",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame.from_dict(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ce271-879a-4d76-9470-518325d14980",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a2004-e98c-42bc-b883-886f8e400d1b",
   "metadata": {},
   "source": [
    "### Remote execution\n",
    "We can execute the function as batch job on the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95190d3b-fac2-4487-95cb-637d7497fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download = func.run(action=\"job\",inputs={\"url\":di.key},outputs={\"dataset\":\"dataset\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90c69c-6857-4a62-b0e5-0666b480c4ab",
   "metadata": {},
   "source": [
    "Wait the run to finish. Monitor the execution status of the run using the console or with the run ``refresh`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087dcd1-0c9a-47ed-941b-9c8d5d60db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download.refresh().status.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4132c32e-ed99-4fd3-bd81-6ef10c807ac1",
   "metadata": {},
   "source": [
    "Let's define additional functions for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa4650-bcaa-4eb1-8ffd-0942c88b0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"extract_parkings.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"parkings\"])\n",
    "def extract_parkings(project, di):\n",
    "    KEYS = ['parcheggio', 'lat', 'lon', 'posti_totali']\n",
    "    df_parcheggi = di.as_df().groupby(['parcheggio']).first().reset_index()[KEYS]\n",
    "    return df_parcheggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9918615-5ec3-490c-979b-1af70d9666ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = proj.new_function(name=\"extract-parkings\",\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"extract_parkings.py\", \"handler\": \"extract_parkings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d63ad-1627-4fdc-8f23-aff96158a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_download = proj.get_dataitem(entity_name=\"dataset\").key\n",
    "run_parkings = func.run(action=\"job\",inputs={\"di\":data_item_download},outputs={\"parkings\":\"parkings\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c904a1-1392-433b-8ec4-a2930b0195c7",
   "metadata": {},
   "source": [
    "Wait the run to finish. Monitor the execution status of the run using the console or with the run ``refresh`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24958d1-b937-4a75-9e0a-9d0a189b9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"aggregations_parkings.py\"\n",
    "from datetime import datetime\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"parking_data_aggregated\"])\n",
    "def aggregate_parkings(project, di):\n",
    "    rdf = di.as_df()\n",
    "    rdf['data'] = pd.to_datetime(rdf['data'])\n",
    "    rdf['day'] = rdf['data'].apply(lambda t: t.replace(second=0, minute=0))\n",
    "    rdf['hour'] = rdf['day'].dt.hour\n",
    "    rdf['dow'] = rdf['day'].dt.dayofweek\n",
    "    #rdf['type'] = rdf['data']#.apply(lambda t: \"sadassad\"+t.astype(str))\n",
    "    rdf['day'] = rdf['day'].apply(lambda t: datetime.timestamp(t)) #added because complain of timestamp not JSOn serializable#\n",
    "    rdf = rdf.drop(columns=['data'])\n",
    "    rdf['lat'] = rdf['lat'].apply(lambda t: float(t))\n",
    "    rdf['lon'] = rdf['lon'].apply(lambda t: float(t))\n",
    "    grouped = rdf.groupby(['parcheggio','day']).mean() #\n",
    "    df_aggregated = grouped.reset_index()\n",
    "    return df_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35f8fc5-bfad-4a7a-a49b-c734b5c5388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = proj.new_function(name=\"aggregate-parkings\",\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"aggregations_parkings.py\", \"handler\": \"aggregate_parkings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e980f-f11e-4817-bb4f-fdcd913b2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_aggregate = func.run(action=\"job\",inputs={\"di\":data_item_download},outputs={\"parking_data_aggregated\":\"parking_data_aggregated\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed805e0-8442-49d2-b866-25d09bfc5729",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"parkings_to_db.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import datetime as dtt\n",
    "import os\n",
    "\n",
    "@handler()\n",
    "def to_db(project, agg_di , parkings_di ):\n",
    "    USERNAME = os.getenv(\"POSTGRES_USER\")#project.get_secret(entity_name='DB_USERNAME').read_secret_value()\n",
    "    PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")#project.get_secret(entity_name='DB_PASSWORD').read_secret_value()\n",
    "    engine = create_engine('postgresql+psycopg2://'+USERNAME+':'+PASSWORD+'@database-postgres-cluster/digitalhub')\n",
    "    \n",
    "    agg_df = agg_di.as_df(file_format=\"parquet\")\n",
    "        \n",
    "    # Keep only last two calendar years\n",
    "    date = dtt.date.today() - dtt.timedelta(days=365*2)\n",
    "    agg_df['day'] = agg_df['day'].apply(lambda t: datetime.fromtimestamp(t)) #added because before was converted the type\n",
    "    agg_df = agg_df[agg_df['day'].dt.date >= date]\n",
    "    agg_df.to_sql(\"parking_data_aggregated\", engine, if_exists=\"replace\")\n",
    "    parkings_di.as_df().to_sql('parkings', engine, if_exists=\"replace\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf61f74-7cf0-4b8c-ac2e-12b96d108112",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = proj.new_function(name=\"to-db\",\n",
    "                         kind=\"python\",\n",
    "                         requirements=[\"sqlalchemy\"],\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"parkings_to_db.py\", \"handler\": \"to_db\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609510c1-ca36-4ed4-8f0d-50515b1701e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_parkings = proj.get_dataitem(entity_name=\"parkings\").key\n",
    "data_item_aggregate = proj.get_dataitem(entity_name=\"parking_data_aggregated\").key\n",
    "\n",
    "run_to_db = func.run(action=\"job\",inputs={\"agg_di\":data_item_aggregate,\"parkings_di\":data_item_parkings},outputs={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7595e41a-bbb5-4e70-91ad-ce3141606d59",
   "metadata": {},
   "source": [
    "### 2.3 Data Management Pipeline\n",
    "We create a data management pipeline that executes the data management functions in the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312d27a-33b1-4fcb-aa25-8ee4524b5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"parkings_pipeline.py\"\n",
    "\n",
    "from digitalhub_runtime_kfp.dsl import pipeline_context\n",
    "\n",
    "def myhandler(url):\n",
    "    with pipeline_context() as pc:\n",
    "        s1_dataset = pc.step(name=\"download\", function=\"downloader-funct\", action=\"job\",inputs={\"url\":url},outputs={\"dataset\":\"dataset\"})\n",
    "        \n",
    "        s2_parking = pc.step(name=\"extract_parking\", function=\"extract-parkings\", action=\"job\",inputs={\"di\":s1_dataset.outputs['dataset']},outputs={\"parkings\":\"parkings\"})\n",
    "        \n",
    "        s3_aggregate = pc.step(name=\"aggregate\",  function=\"aggregate-parkings\", action=\"job\",inputs={\"di\":s1_dataset.outputs['dataset']},outputs={\"parking_data_aggregated\":\"parking_data_aggregated\"})\n",
    "        \n",
    "        s4_to_db = pc.step(name=\"to_db\",  function=\"to-db\", action=\"job\",inputs={\"agg_di\": s3_aggregate.outputs['parking_data_aggregated'],\"parkings_di\":s1_dataset.outputs['dataset']},outputs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5bbf39-85d2-4d22-a914-ca0c14d79fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = proj.new_workflow(name=\"pipeline_parcheggi\", kind=\"kfp\", source={\"source\": \"parkings_pipeline.py\"}, handler=\"myhandler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c7843d-9876-4382-8778-8d581e671cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "di= proj.new_dataitem(name=\"url_data_item\",kind=\"table\",path=URL)\n",
    "workflow_run = workflow.run(parameters={\"url\": di.key})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25339b-8409-4f8f-b631-eb75fa13624f",
   "metadata": {},
   "source": [
    "The execution will take place on the platform using Kubernetes for the execution of single tasks and Kubeflow Pipeline for the orchestration of the data management pipeline.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
