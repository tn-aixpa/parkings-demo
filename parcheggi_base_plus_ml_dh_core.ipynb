{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "\n",
    "### 1.1. Download data\n",
    "Download data from the API, and load it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcheggio</th>\n",
       "      <th>data</th>\n",
       "      <th>posti_liberi</th>\n",
       "      <th>posti_occupati</th>\n",
       "      <th>posti_totali</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07T01:59:00+00:00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-06-07T02:19:00+00:00</td>\n",
       "      <td>486.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07T02:19:00+00:00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-06-07T02:49:00+00:00</td>\n",
       "      <td>488.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07T02:49:00+00:00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10656</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>2024-07-04T10:39:00+00:00</td>\n",
       "      <td>278.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>470</td>\n",
       "      <td>44.501153</td>\n",
       "      <td>11.336062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10657</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-04T10:49:00+00:00</td>\n",
       "      <td>195.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10658</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-04T10:59:00+00:00</td>\n",
       "      <td>187.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10659</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>2024-07-04T10:59:00+00:00</td>\n",
       "      <td>270.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>470</td>\n",
       "      <td>44.501153</td>\n",
       "      <td>11.336062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10660</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-07-03T18:43:00+00:00</td>\n",
       "      <td>200.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10661 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         parcheggio                       data  posti_liberi  posti_occupati  \\\n",
       "0      Autostazione  2024-06-07T01:59:00+00:00         244.0            21.0   \n",
       "1       VIII Agosto  2024-06-07T02:19:00+00:00         486.0           139.0   \n",
       "2      Autostazione  2024-06-07T02:19:00+00:00         244.0            21.0   \n",
       "3       VIII Agosto  2024-06-07T02:49:00+00:00         488.0           137.0   \n",
       "4      Autostazione  2024-06-07T02:49:00+00:00         244.0            21.0   \n",
       "...             ...                        ...           ...             ...   \n",
       "10656     Riva Reno  2024-07-04T10:39:00+00:00         278.0           192.0   \n",
       "10657   VIII Agosto  2024-07-04T10:49:00+00:00         195.0           430.0   \n",
       "10658   VIII Agosto  2024-07-04T10:59:00+00:00         187.0           438.0   \n",
       "10659     Riva Reno  2024-07-04T10:59:00+00:00         270.0           200.0   \n",
       "10660  Autostazione  2024-07-03T18:43:00+00:00         200.0            65.0   \n",
       "\n",
       "       posti_totali        lat        lon  \n",
       "0               265  44.504422  11.346514  \n",
       "1               625  44.500297  11.345368  \n",
       "2               265  44.504422  11.346514  \n",
       "3               625  44.500297  11.345368  \n",
       "4               265  44.504422  11.346514  \n",
       "...             ...        ...        ...  \n",
       "10656           470  44.501153  11.336062  \n",
       "10657           625  44.500297  11.345368  \n",
       "10658           625  44.500297  11.345368  \n",
       "10659           470  44.501153  11.336062  \n",
       "10660           265  44.504422  11.346514  \n",
       "\n",
       "[10661 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://opendata.comune.bologna.it/api/explore/v2.1/catalog/datasets/disponibilita-parcheggi-storico/exports/csv?lang=it&timezone=UTC&use_labels=true&delimiter=%3B\"\n",
    "\n",
    "df = pd.read_csv(URL, sep=\";\")\n",
    "df[['lat', 'lon']] = df['coordinate'].str.split(', ',expand=True)\n",
    "df = df.drop(columns=['% occupazione', 'GUID', 'coordinate']).rename(columns={'Parcheggio': 'parcheggio', 'Data': 'data', 'Posti liberi': 'posti_liberi', 'Posti occupati': 'posti_occupati', 'Posti totali': 'posti_totali'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Extract parkings\n",
    "Extract distinct parkings from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcheggio</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>44.501153</td>\n",
       "      <td>11.336062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     parcheggio        lat        lon\n",
       "0  Autostazione  44.504422  11.346514\n",
       "1     Riva Reno  44.501153  11.336062\n",
       "2   VIII Agosto  44.500297  11.345368"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = ['parcheggio', 'lat', 'lon']\n",
    "df_parcheggi = df.groupby(['parcheggio']).first().reset_index()[KEYS]\n",
    "df_parcheggi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Aggregate Parking Data\n",
    "Aggregate Parking Data by date, hour, dow, and parking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcheggio</th>\n",
       "      <th>day</th>\n",
       "      <th>posti_liberi</th>\n",
       "      <th>posti_occupati</th>\n",
       "      <th>posti_totali</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07 01:00:00+00:00</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07 02:00:00+00:00</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07 03:00:00+00:00</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07 04:00:00+00:00</td>\n",
       "      <td>244.333333</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07 05:00:00+00:00</td>\n",
       "      <td>242.666667</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-04 07:00:00+00:00</td>\n",
       "      <td>440.333333</td>\n",
       "      <td>184.666667</td>\n",
       "      <td>625.0</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-04 08:00:00+00:00</td>\n",
       "      <td>396.166667</td>\n",
       "      <td>228.833333</td>\n",
       "      <td>625.0</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-04 09:00:00+00:00</td>\n",
       "      <td>307.333333</td>\n",
       "      <td>317.666667</td>\n",
       "      <td>625.0</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-04 10:00:00+00:00</td>\n",
       "      <td>208.833333</td>\n",
       "      <td>416.166667</td>\n",
       "      <td>625.0</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-04 11:00:00+00:00</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>625.0</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1825 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        parcheggio                       day  posti_liberi  posti_occupati  \\\n",
       "0     Autostazione 2024-06-07 01:00:00+00:00    244.000000       21.000000   \n",
       "1     Autostazione 2024-06-07 02:00:00+00:00    244.000000       21.000000   \n",
       "2     Autostazione 2024-06-07 03:00:00+00:00    244.000000       21.000000   \n",
       "3     Autostazione 2024-06-07 04:00:00+00:00    244.333333       20.666667   \n",
       "4     Autostazione 2024-06-07 05:00:00+00:00    242.666667       22.333333   \n",
       "...            ...                       ...           ...             ...   \n",
       "1820   VIII Agosto 2024-07-04 07:00:00+00:00    440.333333      184.666667   \n",
       "1821   VIII Agosto 2024-07-04 08:00:00+00:00    396.166667      228.833333   \n",
       "1822   VIII Agosto 2024-07-04 09:00:00+00:00    307.333333      317.666667   \n",
       "1823   VIII Agosto 2024-07-04 10:00:00+00:00    208.833333      416.166667   \n",
       "1824   VIII Agosto 2024-07-04 11:00:00+00:00    171.000000      454.000000   \n",
       "\n",
       "      posti_totali        lat        lon  \n",
       "0            265.0  44.504422  11.346514  \n",
       "1            265.0  44.504422  11.346514  \n",
       "2            265.0  44.504422  11.346514  \n",
       "3            265.0  44.504422  11.346514  \n",
       "4            265.0  44.504422  11.346514  \n",
       "...            ...        ...        ...  \n",
       "1820         625.0  44.500297  11.345368  \n",
       "1821         625.0  44.500297  11.345368  \n",
       "1822         625.0  44.500297  11.345368  \n",
       "1823         625.0  44.500297  11.345368  \n",
       "1824         625.0  44.500297  11.345368  \n",
       "\n",
       "[1825 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = df.copy()\n",
    "rdf['data'] = pd.to_datetime(rdf['data'])\n",
    "rdf['day'] = rdf['data'].apply(lambda t: t.replace(second=0, minute=0))\n",
    "rdf['lat'] = rdf['lat'].apply(lambda t: float(t))\n",
    "rdf['lon'] = rdf['lon'].apply(lambda t: float(t))\n",
    "rdf = rdf.drop(columns=['data'])\n",
    "grouped =rdf.groupby(['parcheggio','day']).mean()\n",
    "df_aggregated = grouped.reset_index()\n",
    "df_aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Platform Support - Data Ops\n",
    "\n",
    "We use the platform support to load the data into the platform, version it, and automate the execution of the data management operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Initalization\n",
    "Create the working context: data management project for the parking data processing. Project is a placeholder for the code, data, and management of the parking data operations. To keep it reproducible, we use the `git` source type to store the definition and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "\n",
    "PROJECT_NAME = \"parcheggi\"\n",
    "proj = dh.get_or_create_project(PROJECT_NAME) # source=\"git://github.com/scc-digitalhub/gdb-project-parkings.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data management functions\n",
    "We convert the data management ETL operations into functions - single executable operations that can be executed in the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/download_all_dh_core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/download_all_dh_core.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"dataset\"])\n",
    "def downloader(project, url):\n",
    "    df = url.as_df(file_format='csv',sep=\";\")\n",
    "    df[['lat', 'lon']] = df['coordinate'].str.split(', ',expand=True)\n",
    "    df = df.drop(columns=['% occupazione', 'GUID', 'coordinate']).rename(columns={'Parcheggio': 'parcheggio', 'Data': 'data', 'Posti liberi': 'posti_liberi', 'Posti occupati': 'posti_occupati', 'Posti totali': 'posti_totali'})\n",
    "    df[\"lat\"] = pd.to_numeric(df[\"lat\"])\n",
    "    df[\"lon\"] = pd.to_numeric(df[\"lon\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"downloader-funct\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"src/download_all_dh_core.py\", \"handler\": \"downloader\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "di= proj.new_dataitem(name=\"url_data_item\",kind=\"table\",path=URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 09:13:30,525 - INFO - Validating task.\n",
      "2024-07-04 09:13:30,526 - INFO - Validating run.\n",
      "2024-07-04 09:13:30,527 - INFO - Starting task.\n",
      "2024-07-04 09:13:30,527 - INFO - Configuring execution.\n",
      "2024-07-04 09:13:30,528 - INFO - Composing function arguments.\n",
      "2024-07-04 09:13:30,570 - INFO - Executing run.\n",
      "2024-07-04 09:13:34,337 - INFO - Task completed, returning run status.\n"
     ]
    }
   ],
   "source": [
    "run_download = func.run(action=\"job\",local_execution=True,inputs={\"url\":di.key},outputs={\"dataset\":\"dataset\"})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'COMPLETED', 'outputs': {'dataset': 'store://parcheggi/dataitems/table/dataset:8c4f48fe-6e9c-481e-8107-e46628d36540'}, 'results': {}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_download.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'parcheggi', 'id': 'e1bde4af-68a7-4fc6-8c78-1f2f47b27322', 'kind': 'python+run', 'key': 'store://parcheggi/runs/python+run/e1bde4af-68a7-4fc6-8c78-1f2f47b27322', 'metadata': {'project': 'parcheggi', 'name': 'e1bde4af-68a7-4fc6-8c78-1f2f47b27322', 'created': '2024-07-04T09:13:30.452Z', 'updated': '2024-07-04T09:13:34.368Z', 'created_by': 'tenant1userid', 'updated_by': 'tenant1userid'}, 'spec': {'task': 'python+job://parcheggi/downloader-funct:93db310d-a03a-4d7b-9807-6902974f3227', 'local_execution': True, 'source': {'source': 'src/download_all_dh_core.py', 'handler': 'downloader', 'base64': 'ZnJvbSBkaWdpdGFsaHViX3J1bnRpbWVfcHl0aG9uIGltcG9ydCBoYW5kbGVyCmltcG9ydCBwYW5kYXMgYXMgcGQKCkBoYW5kbGVyKG91dHB1dHM9WyJkYXRhc2V0Il0pCmRlZiBkb3dubG9hZGVyKHByb2plY3QsIHVybCk6CiAgICBkZiA9IHVybC5hc19kZihmaWxlX2Zvcm1hdD0nY3N2JyxzZXA9IjsiKQogICAgZGZbWydsYXQnLCAnbG9uJ11dID0gZGZbJ2Nvb3JkaW5hdGUnXS5zdHIuc3BsaXQoJywgJyxleHBhbmQ9VHJ1ZSkKICAgIGRmID0gZGYuZHJvcChjb2x1bW5zPVsnJSBvY2N1cGF6aW9uZScsICdHVUlEJywgJ2Nvb3JkaW5hdGUnXSkucmVuYW1lKGNvbHVtbnM9eydQYXJjaGVnZ2lvJzogJ3BhcmNoZWdnaW8nLCAnRGF0YSc6ICdkYXRhJywgJ1Bvc3RpIGxpYmVyaSc6ICdwb3N0aV9saWJlcmknLCAnUG9zdGkgb2NjdXBhdGknOiAncG9zdGlfb2NjdXBhdGknLCAnUG9zdGkgdG90YWxpJzogJ3Bvc3RpX3RvdGFsaSd9KQogICAgZGZbImxhdCJdID0gcGQudG9fbnVtZXJpYyhkZlsibGF0Il0pCiAgICBkZlsibG9uIl0gPSBwZC50b19udW1lcmljKGRmWyJsb24iXSkKICAgIHJldHVybiBkZgo=', 'lang': 'python'}, 'python_version': 'PYTHON3_9', 'function': 'python://parcheggi/downloader-funct:93db310d-a03a-4d7b-9807-6902974f3227', 'inputs': {'url': 'store://parcheggi/dataitems/table/url_data_item:63d608d6-f65c-41b1-b92c-59d25d1c6d99'}, 'outputs': {'dataset': 'dataset'}, 'parameters': {}}, 'status': {'state': 'COMPLETED', 'outputs': {'dataset': 'store://parcheggi/dataitems/table/dataset:8c4f48fe-6e9c-481e-8107-e46628d36540'}, 'results': {}}, 'user': 'tenant1userid'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_download.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_download = run_download.outputs()['dataset'].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/extract_parkings_dh_core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/extract_parkings_dh_core.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"parkings\"])\n",
    "def extract_parkings(project, di):\n",
    "    KEYS = ['parcheggio', 'lat', 'lon', 'posti_totali']\n",
    "    df_parcheggi = di.as_df().groupby(['parcheggio']).first().reset_index()[KEYS]\n",
    "    return df_parcheggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"extract-parkings\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"src/extract_parkings_dh_core.py\", \"handler\": \"extract_parkings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 09:13:34,716 - INFO - Validating task.\n",
      "2024-07-04 09:13:34,717 - INFO - Validating run.\n",
      "2024-07-04 09:13:34,717 - INFO - Starting task.\n",
      "2024-07-04 09:13:34,718 - INFO - Configuring execution.\n",
      "2024-07-04 09:13:34,719 - INFO - Composing function arguments.\n",
      "2024-07-04 09:13:34,759 - INFO - Executing run.\n",
      "2024-07-04 09:13:34,870 - INFO - Task completed, returning run status.\n"
     ]
    }
   ],
   "source": [
    "run_parkings = func.run(action=\"job\",local_execution=True,inputs={\"di\":data_item_download},outputs={\"parkings\":\"parkings\"})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_parkings = run_parkings.outputs()['parkings'].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/aggregations_parkings_dh_core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/aggregations_parkings_dh_core.py\"\n",
    "from datetime import datetime\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"parking_data_aggregated\"])\n",
    "def aggregate_parkings(project, di):\n",
    "    rdf = di.as_df()\n",
    "    rdf['data'] = pd.to_datetime(rdf['data'])\n",
    "    rdf['day'] = rdf['data'].apply(lambda t: t.replace(second=0, minute=0))\n",
    "    rdf['hour'] = rdf['day'].dt.hour\n",
    "    rdf['dow'] = rdf['day'].dt.dayofweek\n",
    "    #rdf['type'] = rdf['data']#.apply(lambda t: \"sadassad\"+t.astype(str))\n",
    "    rdf['day'] = rdf['day'].apply(lambda t: datetime.timestamp(t)) #added because complain of timestamp not JSOn serializable#\n",
    "    rdf = rdf.drop(columns=['data'])\n",
    "    rdf['lat'] = rdf['lat'].apply(lambda t: float(t))\n",
    "    rdf['lon'] = rdf['lon'].apply(lambda t: float(t))\n",
    "    grouped = rdf.groupby(['parcheggio','day']).mean() #\n",
    "    df_aggregated = grouped.reset_index()\n",
    "    return df_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"aggregate-parkings\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"src/aggregations_parkings_dh_core.py\", \"handler\": \"aggregate_parkings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data_item = run.outputs()['dataset'].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 09:13:35,237 - INFO - Validating task.\n",
      "2024-07-04 09:13:35,238 - INFO - Validating run.\n",
      "2024-07-04 09:13:35,239 - INFO - Starting task.\n",
      "2024-07-04 09:13:35,239 - INFO - Configuring execution.\n",
      "2024-07-04 09:13:35,241 - INFO - Composing function arguments.\n",
      "2024-07-04 09:13:35,284 - INFO - Executing run.\n",
      "2024-07-04 09:13:35,454 - INFO - Task completed, returning run status.\n"
     ]
    }
   ],
   "source": [
    "run_aggregate = func.run(action=\"job\",local_execution=True,inputs={\"di\":data_item_download},outputs={\"parking_data_aggregated\":\"parking_data_aggregated\"})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'COMPLETED', 'outputs': {'parking_data_aggregated': 'store://parcheggi/dataitems/table/parking_data_aggregated:7ab9245e-d0b9-492b-876f-85201ff3d2dd'}, 'results': {}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_aggregate.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_aggregate = run_aggregate.outputs()['parking_data_aggregated'].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcheggio</th>\n",
       "      <th>day</th>\n",
       "      <th>posti_liberi</th>\n",
       "      <th>posti_occupati</th>\n",
       "      <th>posti_totali</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>1.717722e+09</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>1.717726e+09</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>1.717729e+09</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>1.717733e+09</td>\n",
       "      <td>244.333333</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>1.717736e+09</td>\n",
       "      <td>242.666667</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     parcheggio           day  posti_liberi  posti_occupati  posti_totali  \\\n",
       "0  Autostazione  1.717722e+09    244.000000       21.000000         265.0   \n",
       "1  Autostazione  1.717726e+09    244.000000       21.000000         265.0   \n",
       "2  Autostazione  1.717729e+09    244.000000       21.000000         265.0   \n",
       "3  Autostazione  1.717733e+09    244.333333       20.666667         265.0   \n",
       "4  Autostazione  1.717736e+09    242.666667       22.333333         265.0   \n",
       "\n",
       "         lat        lon  hour  dow  \n",
       "0  44.504422  11.346514   1.0  4.0  \n",
       "1  44.504422  11.346514   2.0  4.0  \n",
       "2  44.504422  11.346514   3.0  4.0  \n",
       "3  44.504422  11.346514   4.0  4.0  \n",
       "4  44.504422  11.346514   5.0  4.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 09:13:35,937 - INFO - Validating task.\n",
      "2024-07-04 09:13:35,938 - INFO - Validating run.\n",
      "2024-07-04 09:13:35,938 - INFO - Starting task.\n",
      "2024-07-04 09:13:35,939 - INFO - Configuring execution.\n",
      "2024-07-04 09:13:35,941 - INFO - Composing function arguments.\n",
      "2024-07-04 09:13:35,986 - INFO - Executing run.\n"
     ]
    }
   ],
   "source": [
    "run_aggregate.outputs()['parking_data_aggregated'].as_df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digitalhub_owner_user xoMcxHOcwniCoxtBLOsewlzsUD112yeukJHSn69Nj0zs7vKR5HqAaxYQbys51Pnl\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"POSTGRES_USER\"),os.getenv(\"POSTGRES_PASSWORD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/parkings_to_db.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/parkings_to_db.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "import datetime as dtt\n",
    "import os\n",
    "\n",
    "@handler()\n",
    "def to_db(project, agg_di , parkings_di ):\n",
    "    USERNAME = os.getenv(\"POSTGRES_USER\")#project.get_secret(entity_name='DB_USERNAME').read_secret_value()\n",
    "    PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")#project.get_secret(entity_name='DB_PASSWORD').read_secret_value()\n",
    "    engine = create_engine('postgresql://'+USERNAME+':'+PASSWORD+'@database-postgres-cluster/digitalhub')\n",
    "    agg_df = agg_di.as_df()\n",
    "    # Keep only last two calendar years\n",
    "    date = dtt.date.today() - dtt.timedelta(days=365*2)\n",
    "    agg_df['day'] = agg_df['day'].apply(lambda t: datetime.fromtimestamp(t)) #added because before was converted the type\n",
    "    agg_df = agg_df[agg_df['day'].dt.date >= date]\n",
    "    with engine.connect() as connection: \n",
    "        try: \n",
    "            connection.execute(\"DELETE FROM parkings\")\n",
    "        except: \n",
    "            pass\n",
    "        try:\n",
    "            connection.execute(\"DELETE FROM parking_data_aggregated\")\n",
    "        except: \n",
    "            pass\n",
    "    agg_df.to_sql(\"parking_data_aggregated\", engine, if_exists=\"append\")\n",
    "    parkings_di.as_df().to_sql('parkings', engine, if_exists=\"append\")\n",
    "    print(\"done\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"to-db\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         #requirements=[\"sqlalchemy\"]\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"src/parkings_to_db.py\", \"handler\": \"to_db\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set secrets\n",
    "#secret_a = proj.new_secret(name=\"DB_USERNAME_NEW\", secret_value=\"digitalhub_owner_user\")\n",
    "#secret_b = proj.new_secret(name=\"DB_PASSWORD\", secret_value=\"secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 09:14:19,735 - INFO - Validating task.\n",
      "2024-07-04 09:14:19,736 - INFO - Validating run.\n",
      "2024-07-04 09:14:19,736 - INFO - Starting task.\n",
      "2024-07-04 09:14:19,737 - INFO - Configuring execution.\n",
      "2024-07-04 09:14:19,739 - INFO - Composing function arguments.\n",
      "2024-07-04 09:14:19,803 - INFO - Executing run.\n",
      "2024-07-04 09:14:19,987 - INFO - Task completed, returning run status.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "run_to_db = func.run(action=\"job\",local_execution=True,inputs={\"agg_di\":data_item_aggregate,\"parkings_di\":data_item_parkings},outputs={})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_to_db.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_to_db.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Management Pipeline\n",
    "We create a data management pipeline that executes the data management functions in the platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%writefile \"src/parking_data_pipeline.py\"\n",
    "\n",
    "from kfp import dsl\n",
    "from digitalhub_runtime_python import handler\n",
    "import digitalhub as dh\n",
    "\n",
    "URL = \"https://opendata.comune.bologna.it/api/explore/v2.1/catalog/datasets/disponibilita-parcheggi-storico/exports/csv?lang=it&timezone=UTC&use_labels=true&delimiter=%3B\"\n",
    "\n",
    "@dsl.pipeline(name=\"Parking data pipeline\")\n",
    "def parking_pipeline():\n",
    "    project = dh.get_current_project()\n",
    "\n",
    "    run_download = project.run_function(\"download-all\",inputs={'url':URL}, outputs=[\"dataset\"])\n",
    "\n",
    "    run_parkings = project.run_function(\"extract-parkings\", inputs={'di':run_download.outputs()[\"dataset\"].key}, outputs=[\"parkings\"])\n",
    "\n",
    "    run_aggregate = project.run_function(\"aggregate-parkings\", inputs={'di':run_download.outputs()[\"dataset\"].key}, outputs=[\"parking_data_aggregated\"])\n",
    "    \n",
    "    project.run_function(\"to-db\", inputs={'agg_di': run_aggregate.outputs()[\"parking_data_aggregated\"].key, 'parkings_di': run_parkings.outputs()[\"parkings\"].key})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proj.set_workflow(\"pipeline\",\"./pipeline.py\", handler=\"pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proj.run(\"pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install darts==0.25.0 pandas==1.4.4 numpy==1.22.4 patsy==0.5.2 scikit-learn==1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataitems = dh.list_dataitems(project=\"parcheggi\")\n",
    "print(dataitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "\n",
    "dataitem = dh.get_dataitem(project=\"parcheggi\",\n",
    "                           entity_name=\"dataset\")\n",
    "df = dataitem.as_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "window = 60\n",
    "\n",
    "df_clean = df.copy()\n",
    "#print(type(df_clean['data'][0]))\n",
    "#df_clean['data'] = pd.to_datetime(df_clean['data'])\n",
    "df_clean.data = pd.to_datetime(df_clean.data, utc=True)\n",
    "#print(type(df_clean['data'][0]))\n",
    "#df_clean.data = df_clean.data.apply(lambda x: x.to_datetime64()) #.astype('datetime64')\n",
    "df_clean['occupied'] = df_clean.posti_occupati / df_clean.posti_totali\n",
    "#df_clean['date_time_slice'] = df_clean.data.dt.round('30min')\n",
    "df_clean['date_time_slice'] = df_clean.data.dt.round('30min').dt.tz_convert(None)\n",
    "df_clean = df_clean[df_clean.date_time_slice >= (datetime.datetime.today() - pd.DateOffset(window))]\n",
    "df_clean = df_clean[df_clean.date_time_slice <= (datetime.datetime.today() - pd.DateOffset(1))]\n",
    "df_clean.posti_occupati = df_clean.apply(lambda x: max(0, min(x['posti_totali'], x['posti_occupati'])), axis=1)\n",
    "df_clean['occupied'] = df_clean.posti_occupati / df_clean.posti_totali\n",
    "df_clean = df_clean.drop(columns=['lat', 'lon', 'data', 'posti_totali', 'posti_liberi', 'posti_occupati'])\n",
    "df_clean#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "\n",
    "split_ratio = 0.8\n",
    "\n",
    "def fill_missing(parc_df):\n",
    "    missing = []  # List to store timestamps for which values could not be filled\n",
    "    temp = pd.Series(parc_df.index.date).value_counts()  # Count the occurrences of each date\n",
    "    temp = temp[temp < 48]  # Filter dates with less than 48 occurrences\n",
    "    temp.sort_index(inplace=True)  # Sort the dates in ascending order\n",
    "    for t in temp.index:  # Iterate through the filtered dates\n",
    "        for h in range(24):  # Iterate through 24 hours\n",
    "            for half_hour in [0, 30]:  # Iterate through 0 and 30 minutes\n",
    "                ts = datetime.datetime(t.year, t.month, t.day, h, half_hour)  # Create a timestamp\n",
    "                if ts not in parc_df.index:  # If the timestamp is missing in the DataFrame\n",
    "                    if ts - datetime.timedelta(days=7) in parc_df.index:  # Check if the previous week's timestamp is available\n",
    "                        parc_df.loc[ts] = parc_df.loc[ts - datetime.timedelta(days=7)].copy()  # Copy values from the previous week\n",
    "                    elif ts + datetime.timedelta(days=7) in parc_df.index:  # Check if the next week's timestamp is available\n",
    "                        parc_df.loc[ts] = parc_df.loc[ts + datetime.timedelta(days=7)].copy()  # Copy values from the next week\n",
    "                    else:\n",
    "                        missing.append(ts)  # If values cannot be filled, add the timestamp to the missing list\n",
    "    return missing \n",
    "\n",
    "\n",
    "def split_dataset(df_clean):\n",
    "    parcheggi = df_clean['parcheggio'].unique()\n",
    "    train_sets, val_sets = [], []\n",
    "\n",
    "    for parcheggio in parcheggi:\n",
    "        parc_df = df_clean[df_clean['parcheggio'] == parcheggio]\n",
    "        parc_df['hour'] = parc_df.date_time_slice.dt.hour\n",
    "        parc_df['dow'] = parc_df.date_time_slice.dt.dayofweek\n",
    "        parc_df = parc_df.drop(columns=['parcheggio'])\n",
    "        parc_df = parc_df.groupby('date_time_slice').agg({'occupied': 'mean', 'hour': 'first', 'dow': 'first'})\n",
    "        fill_missing(parc_df)\n",
    "        #print(\"###############################\")\n",
    "        #print(parc_df)\n",
    "        #print(\"###############################\")\n",
    "        \n",
    "        #print(\"after\")\n",
    "        #print(parc_df)\n",
    "        #print(\"###############################\")\n",
    "        ts = TimeSeries.from_dataframe(parc_df,  value_cols='occupied', freq='30min')\n",
    "        ts_scaled = Scaler().fit_transform(ts)\n",
    "\n",
    "        split = int(len(ts_scaled) * (1 - split_ratio))\n",
    "\n",
    "        train, val = ts_scaled[:-split], ts_scaled[-split:]\n",
    "        train_sets.append(train)\n",
    "        val_sets.append(val)\n",
    "    return train_sets,val_sets\n",
    "train_sets, val_sets = split_dataset(df_clean)    \n",
    "train_sets[0].plot(label='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import NBEATSModel\n",
    "\n",
    "multimodel =  NBEATSModel(\n",
    "        input_chunk_length=24,\n",
    "        output_chunk_length=12,\n",
    "        n_epochs=10,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "multimodel.fit(train_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred = multimodel.predict(n=24, series=train_sets[0][:-24])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "train_sets[0].plot(label=\"actual\")\n",
    "pred.plot(label=\"forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.metrics import mape, smape, mae\n",
    "\n",
    "metrics = {\n",
    "    \"mape\": mape(train_sets[0], pred),\n",
    "    \"smape\": smape(train_sets[0], pred),\n",
    "    \"mae\": mae(train_sets[0], pred)\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "\n",
    "PROJECT_NAME = \"MLparcheggi\"\n",
    "ml_proj = dh.get_or_create_project(PROJECT_NAME) # source=\"git://github.com/scc-digitalhub/gdb-project-parkings.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"src/train_multimodel.py\"\n",
    "\n",
    "import pandas as pd\n",
    "from digitalhub_runtime_python import handler\n",
    "from darts import TimeSeries\n",
    "\n",
    "from darts.models import NBEATSModel\n",
    "from darts.metrics import mape, smape, mae\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from pickle import dumps\n",
    "\n",
    "def fill_missing(parc_df):\n",
    "    missing = []  # List to store timestamps for which values could not be filled\n",
    "    temp = pd.Series(parc_df.index.date).value_counts()  # Count the occurrences of each date\n",
    "    temp = temp[temp < 48]  # Filter dates with less than 48 occurrences\n",
    "    temp.sort_index(inplace=True)  # Sort the dates in ascending order\n",
    "    for t in temp.index:  # Iterate through the filtered dates\n",
    "        for h in range(24):  # Iterate through 24 hours\n",
    "            for half_hour in [0, 30]:  # Iterate through 0 and 30 minutes\n",
    "                ts = datetime.datetime(t.year, t.month, t.day, h, half_hour)  # Create a timestamp\n",
    "                if ts not in parc_df.index:  # If the timestamp is missing in the DataFrame\n",
    "                    if ts - datetime.timedelta(days=7) in parc_df.index:  # Check if the previous week's timestamp is available\n",
    "                        parc_df.loc[ts] = parc_df.loc[ts - datetime.timedelta(days=7)].copy()  # Copy values from the previous week\n",
    "                    elif ts + datetime.timedelta(days=7) in parc_df.index:  # Check if the next week's timestamp is available\n",
    "                        parc_df.loc[ts] = parc_df.loc[ts + datetime.timedelta(days=7)].copy()  # Copy values from the next week\n",
    "                    else:\n",
    "                        missing.append(ts)  # If values cannot be filled, add the timestamp to the missing list\n",
    "    return missing  # Return the list of timestamps for which values could not be filled\n",
    "\n",
    "\n",
    "@handler()\n",
    "def train_model(project, parkings_di,n_epochs: int = 100, window: int = 60, \n",
    "                input_chunk_length: int = 24, output_chunk_length: int = 12, \n",
    "                split_ratio: float = 0.8):\n",
    "\n",
    "    # Load the input data\n",
    "    df_source = parkings_di.as_df()\n",
    "    # Clean the data\n",
    "    df_clean = df_source.copy()\n",
    "    df_clean.data = pd.to_datetime(df_clean.data, utc=True)\n",
    "    df_clean['occupied'] = df_clean.posti_occupati / df_clean.posti_totali\n",
    "    df_clean['date_time_slice'] = df_clean.data.dt.round('30min').dt.tz_convert(None)\n",
    "    df_clean = df_clean[df_clean.date_time_slice >= (datetime.datetime.today() - pd.DateOffset(window))]\n",
    "    df_clean = df_clean[df_clean.date_time_slice <= (datetime.datetime.today() - pd.DateOffset(1))]\n",
    "    df_clean.posti_occupati = df_clean.apply(lambda x: max(0, min(x['posti_totali'], x['posti_occupati'])), axis=1)\n",
    "    df_clean['occupied'] = df_clean.posti_occupati / df_clean.posti_totali\n",
    "    df_clean = df_clean.drop(columns=['lat', 'lon', 'data', 'posti_totali', 'posti_liberi', 'posti_occupati'])\n",
    "    parcheggi = df_clean['parcheggio'].unique()\n",
    "\n",
    "    train_sets, val_sets = [], []\n",
    "\n",
    "    # Process data for each parking lot\n",
    "    for parcheggio in parcheggi:\n",
    "        parc_df = df_clean[df_clean['parcheggio'] == parcheggio]\n",
    "        parc_df['hour'] = parc_df.date_time_slice.dt.hour\n",
    "        parc_df['dow'] = parc_df.date_time_slice.dt.dayofweek\n",
    "        parc_df = parc_df.drop(columns=['parcheggio'])\n",
    "        parc_df = parc_df.groupby('date_time_slice').agg({'occupied': 'mean', 'hour': 'first', 'dow': 'first'})\n",
    "        fill_missing(parc_df)\n",
    "        ts = TimeSeries.from_dataframe(parc_df,  value_cols='occupied', freq='30min')\n",
    "        ts_scaled = Scaler().fit_transform(ts)\n",
    "        \n",
    "        split = int(len(ts_scaled) * (1 - split_ratio))\n",
    "\n",
    "        # Split data into training and validation sets\n",
    "        train, val = ts_scaled[:-split], ts_scaled[-split:]\n",
    "        train_sets.append(train)\n",
    "        val_sets.append(val)\n",
    "\n",
    "    # Train a multi-model using the NBEATS algorithm\n",
    "    multimodel =  NBEATSModel(\n",
    "        input_chunk_length=input_chunk_length,\n",
    "        output_chunk_length=output_chunk_length,\n",
    "        n_epochs=n_epochs,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Fit the model to the training sets\n",
    "    multimodel.fit(train_sets)\n",
    "    pred = multimodel.predict(n=output_chunk_length*2, series=train_sets[0][:-output_chunk_length*2])\n",
    "\n",
    "    multimodel.save(\"parcheggi_predictor_model.pt\")\n",
    "    with ZipFile(\"parcheggi_predictor_model.pt.zip\", \"w\") as z:\n",
    "        z.write(\"parcheggi_predictor_model.pt\")\n",
    "        z.write(\"parcheggi_predictor_model.pt.ckpt\")\n",
    "\n",
    "    # log model to MLRun\n",
    "    context.log_model(\n",
    "        \"parcheggi_predictor_model\",\n",
    "        parameters={\n",
    "            \"window\": window,\n",
    "            \"input_chunk_length\": input_chunk_length,\n",
    "            \"output_chunk_length\": output_chunk_length,\n",
    "            \"n_epochs\": n_epochs,\n",
    "            \"split_ratio\": split_ratio,\n",
    "            \"num_layers\": multimodel.num_layers,\n",
    "            \"layer_widths\": multimodel.layer_widths,\n",
    "            \"activation\": multimodel.activation\n",
    "        },\n",
    "        metrics = {\n",
    "            \"mape\": mape(train_sets[0], pred),\n",
    "            \"smape\": smape(train_sets[0], pred),\n",
    "            \"mae\": mae(train_sets[0], pred)\n",
    "        },\n",
    "        model_file=\"parcheggi_predictor_model.pt.zip\",\n",
    "        labels={\"class\": \"darts.models.NBEATSModel\"},\n",
    "        algorithm=\"darts.models.NBEATSModel\",\n",
    "        framework=\"darts\"\n",
    "    ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"training_model\"\n",
    "func = ml_proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         #requirements =[\"darts==0.25.0\", \"pandas==1.4.4\", \"numpy==1.22.4\", \"patsy==0.5.2\", \"scikit-learn==1.1.2\"],\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"src/train_multimodel.py\", \"handler\": \"train_model\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_download # relative to the parkings above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_train_model = func.run(action=\"job\",local_execution=True,inputs={\"parkings_di\":data_item_download},outputs={})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digitalhub-core",
   "language": "python",
   "name": "digitalhub-core"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
