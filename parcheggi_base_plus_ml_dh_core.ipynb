{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "\n",
    "### 1.1. Download data\n",
    "Download data from the API, and load it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcheggio</th>\n",
       "      <th>data</th>\n",
       "      <th>posti_liberi</th>\n",
       "      <th>posti_occupati</th>\n",
       "      <th>posti_totali</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07T01:59:00+00:00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-06-07T02:19:00+00:00</td>\n",
       "      <td>486.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07T02:19:00+00:00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-06-07T02:49:00+00:00</td>\n",
       "      <td>488.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07T02:49:00+00:00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-02T08:39:00+00:00</td>\n",
       "      <td>367.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>2024-07-02T08:39:00+00:00</td>\n",
       "      <td>329.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>470</td>\n",
       "      <td>44.501153</td>\n",
       "      <td>11.336062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-02T08:49:00+00:00</td>\n",
       "      <td>359.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10015</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-02T09:09:00+00:00</td>\n",
       "      <td>325.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>2024-07-02T09:19:00+00:00</td>\n",
       "      <td>309.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>470</td>\n",
       "      <td>44.501153</td>\n",
       "      <td>11.336062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10017 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         parcheggio                       data  posti_liberi  posti_occupati  \\\n",
       "0      Autostazione  2024-06-07T01:59:00+00:00         244.0            21.0   \n",
       "1       VIII Agosto  2024-06-07T02:19:00+00:00         486.0           139.0   \n",
       "2      Autostazione  2024-06-07T02:19:00+00:00         244.0            21.0   \n",
       "3       VIII Agosto  2024-06-07T02:49:00+00:00         488.0           137.0   \n",
       "4      Autostazione  2024-06-07T02:49:00+00:00         244.0            21.0   \n",
       "...             ...                        ...           ...             ...   \n",
       "10012   VIII Agosto  2024-07-02T08:39:00+00:00         367.0           258.0   \n",
       "10013     Riva Reno  2024-07-02T08:39:00+00:00         329.0           141.0   \n",
       "10014   VIII Agosto  2024-07-02T08:49:00+00:00         359.0           266.0   \n",
       "10015   VIII Agosto  2024-07-02T09:09:00+00:00         325.0           300.0   \n",
       "10016     Riva Reno  2024-07-02T09:19:00+00:00         309.0           161.0   \n",
       "\n",
       "       posti_totali        lat        lon  \n",
       "0               265  44.504422  11.346514  \n",
       "1               625  44.500297  11.345368  \n",
       "2               265  44.504422  11.346514  \n",
       "3               625  44.500297  11.345368  \n",
       "4               265  44.504422  11.346514  \n",
       "...             ...        ...        ...  \n",
       "10012           625  44.500297  11.345368  \n",
       "10013           470  44.501153  11.336062  \n",
       "10014           625  44.500297  11.345368  \n",
       "10015           625  44.500297  11.345368  \n",
       "10016           470  44.501153  11.336062  \n",
       "\n",
       "[10017 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://opendata.comune.bologna.it/api/explore/v2.1/catalog/datasets/disponibilita-parcheggi-storico/exports/csv?lang=it&timezone=UTC&use_labels=true&delimiter=%3B\"\n",
    "\n",
    "df = pd.read_csv(URL, sep=\";\")\n",
    "df[['lat', 'lon']] = df['coordinate'].str.split(', ',expand=True)\n",
    "df = df.drop(columns=['% occupazione', 'GUID', 'coordinate']).rename(columns={'Parcheggio': 'parcheggio', 'Data': 'data', 'Posti liberi': 'posti_liberi', 'Posti occupati': 'posti_occupati', 'Posti totali': 'posti_totali'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Extract parkings\n",
    "Extract distinct parkings from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcheggio</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>44.501153</td>\n",
       "      <td>11.336062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     parcheggio        lat        lon\n",
       "0  Autostazione  44.504422  11.346514\n",
       "1     Riva Reno  44.501153  11.336062\n",
       "2   VIII Agosto  44.500297  11.345368"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KEYS = ['parcheggio', 'lat', 'lon']\n",
    "df_parcheggi = df.groupby(['parcheggio']).first().reset_index()[KEYS]\n",
    "df_parcheggi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Aggregate Parking Data\n",
    "Aggregate Parking Data by date, hour, dow, and parking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcheggio</th>\n",
       "      <th>day</th>\n",
       "      <th>posti_liberi</th>\n",
       "      <th>posti_occupati</th>\n",
       "      <th>posti_totali</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07 01:00:00+00:00</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07 02:00:00+00:00</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07 03:00:00+00:00</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07 04:00:00+00:00</td>\n",
       "      <td>244.333333</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07 05:00:00+00:00</td>\n",
       "      <td>242.666667</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>265.0</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-02 05:00:00+00:00</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>625.0</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-02 06:00:00+00:00</td>\n",
       "      <td>438.500000</td>\n",
       "      <td>186.500000</td>\n",
       "      <td>625.0</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-02 07:00:00+00:00</td>\n",
       "      <td>431.833333</td>\n",
       "      <td>193.166667</td>\n",
       "      <td>625.0</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-02 08:00:00+00:00</td>\n",
       "      <td>375.500000</td>\n",
       "      <td>249.500000</td>\n",
       "      <td>625.0</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-07-02 09:00:00+00:00</td>\n",
       "      <td>312.500000</td>\n",
       "      <td>312.500000</td>\n",
       "      <td>625.0</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        parcheggio                       day  posti_liberi  posti_occupati  \\\n",
       "0     Autostazione 2024-06-07 01:00:00+00:00    244.000000       21.000000   \n",
       "1     Autostazione 2024-06-07 02:00:00+00:00    244.000000       21.000000   \n",
       "2     Autostazione 2024-06-07 03:00:00+00:00    244.000000       21.000000   \n",
       "3     Autostazione 2024-06-07 04:00:00+00:00    244.333333       20.666667   \n",
       "4     Autostazione 2024-06-07 05:00:00+00:00    242.666667       22.333333   \n",
       "...            ...                       ...           ...             ...   \n",
       "1705   VIII Agosto 2024-07-02 05:00:00+00:00    440.000000      185.000000   \n",
       "1706   VIII Agosto 2024-07-02 06:00:00+00:00    438.500000      186.500000   \n",
       "1707   VIII Agosto 2024-07-02 07:00:00+00:00    431.833333      193.166667   \n",
       "1708   VIII Agosto 2024-07-02 08:00:00+00:00    375.500000      249.500000   \n",
       "1709   VIII Agosto 2024-07-02 09:00:00+00:00    312.500000      312.500000   \n",
       "\n",
       "      posti_totali        lat        lon  \n",
       "0            265.0  44.504422  11.346514  \n",
       "1            265.0  44.504422  11.346514  \n",
       "2            265.0  44.504422  11.346514  \n",
       "3            265.0  44.504422  11.346514  \n",
       "4            265.0  44.504422  11.346514  \n",
       "...            ...        ...        ...  \n",
       "1705         625.0  44.500297  11.345368  \n",
       "1706         625.0  44.500297  11.345368  \n",
       "1707         625.0  44.500297  11.345368  \n",
       "1708         625.0  44.500297  11.345368  \n",
       "1709         625.0  44.500297  11.345368  \n",
       "\n",
       "[1710 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = df.copy()\n",
    "rdf['data'] = pd.to_datetime(rdf['data'])\n",
    "rdf['day'] = rdf['data'].apply(lambda t: t.replace(second=0, minute=0))\n",
    "rdf['lat'] = rdf['lat'].apply(lambda t: float(t))\n",
    "rdf['lon'] = rdf['lon'].apply(lambda t: float(t))\n",
    "rdf = rdf.drop(columns=['data'])\n",
    "grouped =rdf.groupby(['parcheggio','day']).mean()\n",
    "df_aggregated = grouped.reset_index()\n",
    "df_aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Platform Support - Data Ops\n",
    "\n",
    "We use the platform support to load the data into the platform, version it, and automate the execution of the data management operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Initalization\n",
    "Create the working context: data management project for the parking data processing. Project is a placeholder for the code, data, and management of the parking data operations. To keep it reproducible, we use the `git` source type to store the definition and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "\n",
    "PROJECT_NAME = \"parcheggi\"\n",
    "proj = dh.get_or_create_project(PROJECT_NAME) # source=\"git://github.com/scc-digitalhub/gdb-project-parkings.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data management functions\n",
    "We convert the data management ETL operations into functions - single executable operations that can be executed in the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/download_all_dh_core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/download_all_dh_core.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"dataset\"])\n",
    "def downloader(project, url):\n",
    "    df = url.as_df(file_format='csv',sep=\";\")\n",
    "    df[['lat', 'lon']] = df['coordinate'].str.split(', ',expand=True)\n",
    "    df = df.drop(columns=['% occupazione', 'GUID', 'coordinate']).rename(columns={'Parcheggio': 'parcheggio', 'Data': 'data', 'Posti liberi': 'posti_liberi', 'Posti occupati': 'posti_occupati', 'Posti totali': 'posti_totali'})\n",
    "    df[\"lat\"] = pd.to_numeric(df[\"lat\"])\n",
    "    df[\"lon\"] = pd.to_numeric(df[\"lon\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"downloader-funct\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"src/download_all_dh_core.py\", \"handler\": \"downloader\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "di= proj.new_dataitem(name=\"url_data_item\",kind=\"table\",path=URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 07:41:12,202 - INFO - Validating task.\n",
      "2024-07-02 07:41:12,202 - INFO - Validating run.\n",
      "2024-07-02 07:41:12,203 - INFO - Starting task.\n",
      "2024-07-02 07:41:12,203 - INFO - Configuring execution.\n",
      "2024-07-02 07:41:12,205 - INFO - Composing function arguments.\n",
      "2024-07-02 07:41:12,206 - INFO - Function parameters: True\n",
      "2024-07-02 07:41:12,261 - INFO - Executing run.\n",
      "2024-07-02 07:41:23,015 - INFO - Task completed, returning run status.\n"
     ]
    }
   ],
   "source": [
    "run_download = func.run(action=\"job\",local_execution=True,inputs={\"url\":di.key},outputs={\"dataset\":\"dataset\"})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'COMPLETED', 'outputs': {'dataset': 'store://parcheggi/dataitems/table/dataset:f259bfd4-7a44-4efb-8a2d-43be2f09935f'}, 'results': {}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_download.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'parcheggi', 'id': 'ebe3d7f5-9c63-4fb3-92c1-f2529dd965f0', 'kind': 'python+run', 'key': 'store://parcheggi/runs/python+run/ebe3d7f5-9c63-4fb3-92c1-f2529dd965f0', 'metadata': {'project': 'parcheggi', 'name': 'ebe3d7f5-9c63-4fb3-92c1-f2529dd965f0', 'created': '2024-07-02T07:41:12.139Z', 'updated': '2024-07-02T07:41:23.069Z', 'created_by': 'tenant1userid', 'updated_by': 'tenant1userid'}, 'spec': {'task': 'python+job://parcheggi/downloader-funct:f19c7610-f7e0-433a-b1f5-51d2af98b693', 'local_execution': True, 'source': {'source': 'src/download_all_dh_core.py', 'handler': 'downloader', 'base64': 'ZnJvbSBkaWdpdGFsaHViX3J1bnRpbWVfcHl0aG9uIGltcG9ydCBoYW5kbGVyCmltcG9ydCBwYW5kYXMgYXMgcGQKCkBoYW5kbGVyKG91dHB1dHM9WyJkYXRhc2V0Il0pCmRlZiBkb3dubG9hZGVyKHByb2plY3QsIHVybCk6CiAgICBkZiA9IHVybC5hc19kZihmaWxlX2Zvcm1hdD0nY3N2JyxzZXA9IjsiKQogICAgZGZbWydsYXQnLCAnbG9uJ11dID0gZGZbJ2Nvb3JkaW5hdGUnXS5zdHIuc3BsaXQoJywgJyxleHBhbmQ9VHJ1ZSkKICAgIGRmID0gZGYuZHJvcChjb2x1bW5zPVsnJSBvY2N1cGF6aW9uZScsICdHVUlEJywgJ2Nvb3JkaW5hdGUnXSkucmVuYW1lKGNvbHVtbnM9eydQYXJjaGVnZ2lvJzogJ3BhcmNoZWdnaW8nLCAnRGF0YSc6ICdkYXRhJywgJ1Bvc3RpIGxpYmVyaSc6ICdwb3N0aV9saWJlcmknLCAnUG9zdGkgb2NjdXBhdGknOiAncG9zdGlfb2NjdXBhdGknLCAnUG9zdGkgdG90YWxpJzogJ3Bvc3RpX3RvdGFsaSd9KQogICAgZGZbImxhdCJdID0gcGQudG9fbnVtZXJpYyhkZlsibGF0Il0pCiAgICBkZlsibG9uIl0gPSBwZC50b19udW1lcmljKGRmWyJsb24iXSkKICAgIHJldHVybiBkZgo=', 'lang': 'python'}, 'python_version': 'PYTHON3_9', 'function': 'python://parcheggi/downloader-funct:f19c7610-f7e0-433a-b1f5-51d2af98b693', 'inputs': {'url': 'store://parcheggi/dataitems/table/url_data_item:22f9a253-d426-49d7-9b02-3ce061893d9a'}, 'outputs': {'dataset': 'dataset'}, 'parameters': {}}, 'status': {'state': 'COMPLETED', 'outputs': {'dataset': 'store://parcheggi/dataitems/table/dataset:f259bfd4-7a44-4efb-8a2d-43be2f09935f'}, 'results': {}}, 'user': 'tenant1userid'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_download.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_download = run_download.outputs()['dataset'].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/extract_parkings_dh_core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/extract_parkings_dh_core.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"parkings\"])\n",
    "def extract_parkings(project, di):\n",
    "    KEYS = ['parcheggio', 'lat', 'lon', 'posti_totali']\n",
    "    df_parcheggi = di.as_df().groupby(['parcheggio']).first().reset_index()[KEYS]\n",
    "    return df_parcheggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"extract-parkings\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"src/extract_parkings_dh_core.py\", \"handler\": \"extract_parkings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 07:42:13,053 - INFO - Validating task.\n",
      "2024-07-02 07:42:13,054 - INFO - Validating run.\n",
      "2024-07-02 07:42:13,055 - INFO - Starting task.\n",
      "2024-07-02 07:42:13,055 - INFO - Configuring execution.\n",
      "2024-07-02 07:42:13,057 - INFO - Composing function arguments.\n",
      "2024-07-02 07:42:13,058 - INFO - Function parameters: True\n",
      "2024-07-02 07:42:13,096 - INFO - Executing run.\n",
      "2024-07-02 07:42:13,203 - INFO - Task completed, returning run status.\n"
     ]
    }
   ],
   "source": [
    "run_parkings = func.run(action=\"job\",local_execution=True,inputs={\"di\":data_item_download},outputs={\"parkings\":\"parkings\"})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_parkings = run_parkings.outputs()['parkings'].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/aggregations_parkings_dh_core.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/aggregations_parkings_dh_core.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "\n",
    "@handler(outputs=[\"parking_data_aggregated\"])\n",
    "def aggregate_parkings(project, di):\n",
    "    rdf = di.as_df()\n",
    "    rdf['data'] = pd.to_datetime(rdf['data'])\n",
    "    rdf['day'] = rdf['data'].apply(lambda t: t.replace(second=0, minute=0))\n",
    "    rdf['hour'] = rdf['day'].dt.hour\n",
    "    rdf['dow'] = rdf['day'].dt.dayofweek\n",
    "    rdf = rdf.drop(columns=['data'])\n",
    "    rdf['lat'] = rdf['lat'].apply(lambda t: float(t))\n",
    "    rdf['lon'] = rdf['lon'].apply(lambda t: float(t))\n",
    "    grouped = rdf.groupby(['parcheggio','day']).mean()\n",
    "    df_aggregated = grouped.reset_index()\n",
    "    return df_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"aggregate-parkings\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"src/aggregations_parkings_dh_core.py\", \"handler\": \"aggregate_parkings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data_item = run.outputs()['dataset'].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 07:42:39,762 - INFO - Validating task.\n",
      "2024-07-02 07:42:39,762 - INFO - Validating run.\n",
      "2024-07-02 07:42:39,763 - INFO - Starting task.\n",
      "2024-07-02 07:42:39,763 - INFO - Configuring execution.\n",
      "2024-07-02 07:42:39,765 - INFO - Composing function arguments.\n",
      "2024-07-02 07:42:39,766 - INFO - Function parameters: True\n",
      "2024-07-02 07:42:39,795 - INFO - Executing run.\n",
      "2024-07-02 07:42:39,930 - INFO - Task completed, returning run status.\n"
     ]
    }
   ],
   "source": [
    "run_aggregate = func.run(action=\"job\",local_execution=True,inputs={\"di\":data_item_download},outputs={\"parking_data_aggregated\":\"parking_data_aggregated\"})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_aggregate = run_aggregate.outputs()['parking_data_aggregated'].key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digitalhub_owner_user tifE4hLlIUEryXyzQ2XXHnpIB2kM3lXdU8ndAmvJ6DsxvtkO7fgQ4lGwxYJaVfRQ\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"POSTGRES_USER\"),os.getenv(\"POSTGRES_PASSWORD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/parkings_to_db.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/parkings_to_db.py\"\n",
    "from digitalhub_runtime_python import handler\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "@handler()\n",
    "def to_db(project, agg_di , parkings_di ):\n",
    "    USERNAME = os.getenv(\"POSTGRES_USER\")#project.get_secret(entity_name='DB_USERNAME').read_secret_value()\n",
    "    PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")#project.get_secret(entity_name='DB_PASSWORD').read_secret_value()\n",
    "    engine = create_engine('postgresql://'+USERNAME+':'+PASSWORD+'@database-postgres-cluster/digitalhub')\n",
    "    agg_df = agg_di.as_df()\n",
    "    # Keep only last two calendar years\n",
    "    date = datetime.date.today() - datetime.timedelta(days=365*2)\n",
    "    agg_df = agg_df[agg_df['day'].dt.date >= date]\n",
    "    with engine.connect() as connection: \n",
    "        try: connection.execute(\"DELETE FROM parkings\")\n",
    "        except: pass\n",
    "        try: connection.execute(\"DELETE FROM parking_data_aggregated\")\n",
    "        except: pass\n",
    "    agg_df.to_sql(\"parking_data_aggregated\", engine, if_exists=\"append\")\n",
    "    parkings_di.as_df().to_sql('parkings', engine, if_exists=\"append\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_NAME=\"to-db\"\n",
    "func = proj.new_function(name=FUNCTION_NAME,\n",
    "                         kind=\"python\",\n",
    "                         python_version=\"PYTHON3_9\",\n",
    "                         source={\"source\": \"src/parkings_to_db.py\", \"handler\": \"to_db\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set secrets\n",
    "#secret_a = proj.new_secret(name=\"DB_USERNAME_NEW\", secret_value=\"digitalhub_owner_user\")\n",
    "#secret_b = proj.new_secret(name=\"DB_PASSWORD\", secret_value=\"secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 08:56:45,685 - INFO - Validating task.\n",
      "2024-07-02 08:56:45,686 - INFO - Validating run.\n",
      "2024-07-02 08:56:45,686 - INFO - Starting task.\n",
      "2024-07-02 08:56:45,686 - INFO - Configuring execution.\n",
      "2024-07-02 08:56:45,688 - INFO - Composing function arguments.\n",
      "2024-07-02 08:56:45,689 - INFO - Function parameters: True\n",
      "2024-07-02 08:56:45,725 - INFO - Executing run.\n",
      "2024-07-02 08:56:45,961 - INFO - Task completed, returning run status.\n"
     ]
    }
   ],
   "source": [
    "run_to_db = func.run(action=\"job\",local_execution=True,inputs={\"agg_di\":data_item_aggregate,\"parkings_di\":data_item_parkings},outputs={})# local_execution=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'COMPLETED', 'outputs': {}, 'results': {}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_to_db.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'parcheggi', 'id': '6bb986d4-b64c-4ac9-8194-94660b7d96c5', 'kind': 'python+run', 'key': 'store://parcheggi/runs/python+run/6bb986d4-b64c-4ac9-8194-94660b7d96c5', 'metadata': {'project': 'parcheggi', 'name': '6bb986d4-b64c-4ac9-8194-94660b7d96c5', 'created': '2024-07-02T08:56:45.622Z', 'updated': '2024-07-02T08:56:45.992Z', 'created_by': 'tenant1userid', 'updated_by': 'tenant1userid'}, 'spec': {'task': 'python+job://parcheggi/to-db:1068555f-8a3f-4fa0-8b27-d73c8d89a892', 'local_execution': True, 'source': {'source': 'src/parkings_to_db.py', 'handler': 'to_db', 'base64': 'ZnJvbSBkaWdpdGFsaHViX3J1bnRpbWVfcHl0aG9uIGltcG9ydCBoYW5kbGVyCmltcG9ydCBwYW5kYXMgYXMgcGQKZnJvbSBzcWxhbGNoZW15IGltcG9ydCBjcmVhdGVfZW5naW5lCmltcG9ydCBkYXRldGltZQppbXBvcnQgb3MKCkBoYW5kbGVyKCkKZGVmIHRvX2RiKHByb2plY3QsIGFnZ19kaSAsIHBhcmtpbmdzX2RpICk6CiAgICBVU0VSTkFNRSA9IG9zLmdldGVudigiUE9TVEdSRVNfVVNFUiIpI3Byb2plY3QuZ2V0X3NlY3JldChlbnRpdHlfbmFtZT0nREJfVVNFUk5BTUUnKS5yZWFkX3NlY3JldF92YWx1ZSgpCiAgICBQQVNTV09SRCA9IG9zLmdldGVudigiUE9TVEdSRVNfUEFTU1dPUkQiKSNwcm9qZWN0LmdldF9zZWNyZXQoZW50aXR5X25hbWU9J0RCX1BBU1NXT1JEJykucmVhZF9zZWNyZXRfdmFsdWUoKQogICAgZW5naW5lID0gY3JlYXRlX2VuZ2luZSgncG9zdGdyZXNxbDovLycrVVNFUk5BTUUrJzonK1BBU1NXT1JEKydAZGF0YWJhc2UtcG9zdGdyZXMtY2x1c3Rlci9kaWdpdGFsaHViJykKICAgIGFnZ19kZiA9IGFnZ19kaS5hc19kZigpCiAgICAjIEtlZXAgb25seSBsYXN0IHR3byBjYWxlbmRhciB5ZWFycwogICAgZGF0ZSA9IGRhdGV0aW1lLmRhdGUudG9kYXkoKSAtIGRhdGV0aW1lLnRpbWVkZWx0YShkYXlzPTM2NSoyKQogICAgYWdnX2RmID0gYWdnX2RmW2FnZ19kZlsnZGF5J10uZHQuZGF0ZSA+PSBkYXRlXQogICAgd2l0aCBlbmdpbmUuY29ubmVjdCgpIGFzIGNvbm5lY3Rpb246IAogICAgICAgIHRyeTogY29ubmVjdGlvbi5leGVjdXRlKCJERUxFVEUgRlJPTSBwYXJraW5ncyIpCiAgICAgICAgZXhjZXB0OiBwYXNzCiAgICAgICAgdHJ5OiBjb25uZWN0aW9uLmV4ZWN1dGUoIkRFTEVURSBGUk9NIHBhcmtpbmdfZGF0YV9hZ2dyZWdhdGVkIikKICAgICAgICBleGNlcHQ6IHBhc3MKICAgIGFnZ19kZi50b19zcWwoInBhcmtpbmdfZGF0YV9hZ2dyZWdhdGVkIiwgZW5naW5lLCBpZl9leGlzdHM9ImFwcGVuZCIpCiAgICBwYXJraW5nc19kaS5hc19kZigpLnRvX3NxbCgncGFya2luZ3MnLCBlbmdpbmUsIGlmX2V4aXN0cz0iYXBwZW5kIikKICAgIHJldHVybgo=', 'lang': 'python'}, 'python_version': 'PYTHON3_9', 'function': 'python://parcheggi/to-db:1068555f-8a3f-4fa0-8b27-d73c8d89a892', 'inputs': {'agg_di': 'store://parcheggi/dataitems/table/parking_data_aggregated:c8bc209b-93e7-4ba9-a6a7-cb35680e1901', 'parkings_di': 'store://parcheggi/dataitems/table/parkings:8e187428-6f90-499a-a48b-1995b9046ad4'}, 'outputs': {}, 'parameters': {}}, 'status': {'state': 'COMPLETED', 'outputs': {}, 'results': {}}, 'user': 'tenant1userid'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_to_db.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Management Pipeline\n",
    "We create a data management pipeline that executes the data management functions in the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/parking_data_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/parking_data_pipeline.py\"\n",
    "\n",
    "from kfp import dsl\n",
    "from digitalhub_runtime_python import handler\n",
    "import digitalhub as dh\n",
    "\n",
    "URL = \"https://opendata.comune.bologna.it/api/explore/v2.1/catalog/datasets/disponibilita-parcheggi-storico/exports/csv?lang=it&timezone=UTC&use_labels=true&delimiter=%3B\"\n",
    "\n",
    "@dsl.pipeline(name=\"Parking data pipeline\")\n",
    "def parking_pipeline():\n",
    "    project = dh.get_current_project()\n",
    "\n",
    "    run_download = project.run_function(\"download-all\",inputs={'url':URL}, outputs=[\"dataset\"])\n",
    "\n",
    "    run_parkings = project.run_function(\"extract-parkings\", inputs={'di':run_download.outputs()[\"dataset\"].key}, outputs=[\"parkings\"])\n",
    "\n",
    "    run_aggregate = project.run_function(\"aggregate-parkings\", inputs={'di':run_download.outputs()[\"dataset\"].key}, outputs=[\"parking_data_aggregated\"])\n",
    "    \n",
    "    project.run_function(\"to-db\", inputs={'agg_di': run_aggregate.outputs()[\"parking_data_aggregated\"].key, 'parkings_di': run_parkings.outputs()[\"parkings\"].key})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "set_workflow() got an unexpected keyword argument 'handler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mproj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./pipeline.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: set_workflow() got an unexpected keyword argument 'handler'"
     ]
    }
   ],
   "source": [
    "proj.set_workflow(\"pipeline\",\"./pipeline.py\", handler=\"pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.run(\"pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting darts==0.25.0\n",
      "  Downloading darts-0.25.0-py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas==1.4.4\n",
      "  Downloading pandas-1.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting numpy==1.22.4\n",
      "  Downloading numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting patsy==0.5.2\n",
      "  Downloading patsy-0.5.2-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting holidays>=0.11.1 (from darts==0.25.0)\n",
      "  Downloading holidays-0.52-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: joblib>=0.16.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from darts==0.25.0) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from darts==0.25.0) (3.7.3)\n",
      "Collecting nfoursid>=1.0.0 (from darts==0.25.0)\n",
      "  Downloading nfoursid-1.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pmdarima>=1.8.0 (from darts==0.25.0)\n",
      "  Downloading pmdarima-2.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\n",
      "Collecting pyod>=0.9.5 (from darts==0.25.0)\n",
      "  Downloading pyod-2.0.1.tar.gz (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from darts==0.25.0) (2.32.3)\n",
      "Collecting scikit-learn>=1.0.1 (from darts==0.25.0)\n",
      "  Downloading scikit_learn-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from darts==0.25.0) (1.11.4)\n",
      "Collecting shap>=0.40.0 (from darts==0.25.0)\n",
      "  Downloading shap-0.46.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
      "Collecting statsforecast>=1.4 (from darts==0.25.0)\n",
      "  Downloading statsforecast-1.7.5-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: statsmodels>=0.14.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from darts==0.25.0) (0.14.2)\n",
      "Collecting tbats>=1.1.0 (from darts==0.25.0)\n",
      "  Downloading tbats-1.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.60.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from darts==0.25.0) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from darts==0.25.0) (4.12.2)\n",
      "Collecting xarray>=0.17.0 (from darts==0.25.0)\n",
      "  Downloading xarray-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting xgboost>=1.6.0 (from darts==0.25.0)\n",
      "  Downloading xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting pytorch-lightning>=1.5.0 (from darts==0.25.0)\n",
      "  Downloading pytorch_lightning-2.3.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tensorboardX>=2.1 (from darts==0.25.0)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting torch>=1.8.0 (from darts==0.25.0)\n",
      "  Downloading torch-2.3.1-cp39-cp39-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from pandas==1.4.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from pandas==1.4.4) (2024.1)\n",
      "Requirement already satisfied: six in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from patsy==0.5.2) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from matplotlib>=3.3.0->darts==0.25.0) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from matplotlib>=3.3.0->darts==0.25.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from matplotlib>=3.3.0->darts==0.25.0) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from matplotlib>=3.3.0->darts==0.25.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from matplotlib>=3.3.0->darts==0.25.0) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from matplotlib>=3.3.0->darts==0.25.0) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from matplotlib>=3.3.0->darts==0.25.0) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from matplotlib>=3.3.0->darts==0.25.0) (6.4.0)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29 (from pmdarima>=1.8.0->darts==0.25.0)\n",
      "  Downloading Cython-3.0.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from pmdarima>=1.8.0->darts==0.25.0) (1.26.19)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from pmdarima>=1.8.0->darts==0.25.0) (70.1.0)\n",
      "Requirement already satisfied: numba>=0.51 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from pyod>=0.9.5->darts==0.25.0) (0.58.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from pytorch-lightning>=1.5.0->darts==0.25.0) (6.0.1)\n",
      "Collecting fsspec>=2022.5.0 (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.25.0)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.5.0->darts==0.25.0)\n",
      "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=1.5.0->darts==0.25.0)\n",
      "  Downloading lightning_utilities-0.11.3.post0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from requests>=2.22.0->darts==0.25.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from requests>=2.22.0->darts==0.25.0) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from requests>=2.22.0->darts==0.25.0) (2024.6.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.0.1->darts==0.25.0)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting slicer==0.0.8 (from shap>=0.40.0->darts==0.25.0)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from shap>=0.40.0->darts==0.25.0) (2.2.1)\n",
      "Collecting coreforecast>=0.0.9 (from statsforecast>=1.4->darts==0.25.0)\n",
      "  Downloading coreforecast-0.0.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting fugue>=0.8.1 (from statsforecast>=1.4->darts==0.25.0)\n",
      "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting utilsforecast>=0.1.4 (from statsforecast>=1.4->darts==0.25.0)\n",
      "  Downloading utilsforecast-0.1.12-py3-none-any.whl.metadata (7.5 kB)\n",
      "INFO: pip is looking at multiple versions of statsmodels to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting statsmodels>=0.14.0 (from darts==0.25.0)\n",
      "  Downloading statsmodels-0.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)\n",
      "  Downloading statsmodels-0.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: protobuf>=3.20 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from tensorboardX>=2.1->darts==0.25.0) (5.27.1)\n",
      "Collecting filelock (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting sympy (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from torch>=1.8.0->darts==0.25.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from torch>=1.8.0->darts==0.25.0) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.3.1 (from torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading triton-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "INFO: pip is looking at multiple versions of xarray to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting xarray>=0.17.0 (from darts==0.25.0)\n",
      "  Downloading xarray-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2024.1.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading xarray-2023.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.25.0)\n",
      "  Downloading aiohttp-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting triad>=0.9.7 (from fugue>=0.8.1->statsforecast>=1.4->darts==0.25.0)\n",
      "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast>=1.4->darts==0.25.0)\n",
      "  Downloading adagio-0.2.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->darts==0.25.0) (3.19.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from numba>=0.51->pyod>=0.9.5->darts==0.25.0) (0.41.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->darts==0.25.0) (2.1.5)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->torch>=1.8.0->darts==0.25.0)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.25.0)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.25.0) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.25.0)\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.25.0)\n",
      "  Downloading multidict-6.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.25.0)\n",
      "  Downloading yarl-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.5.0->darts==0.25.0)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /opt/conda/envs/digitalhub-core/lib/python3.9/site-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts==0.25.0) (14.0.2)\n",
      "Collecting fs (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts==0.25.0)\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts==0.25.0)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Downloading darts-0.25.0-py3-none-any.whl (760 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.5/760.5 kB\u001b[0m \u001b[31m167.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m188.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m312.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-0.5.2-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.7/233.7 kB\u001b[0m \u001b[31m412.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading holidays-0.52-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m450.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nfoursid-1.0.1-py3-none-any.whl (16 kB)\n",
      "Downloading pmdarima-2.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m308.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.3.1-py3-none-any.whl (812 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m438.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shap-0.46.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (539 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m539.9/539.9 kB\u001b[0m \u001b[31m453.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading statsforecast-1.7.5-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m270.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m168.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m179.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m363.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp39-cp39-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m170.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m159.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m273.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m226.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m404.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m182.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m142.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m133.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m174.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m149.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m145.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m366.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m198.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xarray-2023.12.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m321.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-2.1.0-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m364.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coreforecast-0.0.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.5/223.5 kB\u001b[0m \u001b[31m385.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Cython-3.0.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m323.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m384.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m363.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.3.post0-py3-none-any.whl (26 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m415.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading utilsforecast-0.1.12-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m235.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m348.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading adagio-0.2.4-py3-none-any.whl (26 kB)\n",
      "Downloading aiohttp-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m371.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m413.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m294.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m275.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m437.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m362.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.3/304.3 kB\u001b[0m \u001b[31m323.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m312.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Building wheels for collected packages: pyod\n",
      "  Building wheel for pyod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyod: filename=pyod-2.0.1-py3-none-any.whl size=193268 sha256=2f36f142dd17b3e69d8a152b253bf3b23c4edb79c840c9208930d1c95f3ff6f3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tbzkih_0/wheels/23/71/88/c2bab1baecb9b35930a6087879e2e07c5e663c480fea6c0479\n",
      "Successfully built pyod\n",
      "Installing collected packages: mpmath, appdirs, threadpoolctl, sympy, slicer, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, multidict, lightning-utilities, fsspec, fs, frozenlist, filelock, Cython, async-timeout, yarl, triton, tensorboardX, patsy, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, holidays, coreforecast, aiosignal, xgboost, xarray, utilsforecast, triad, statsmodels, scikit-learn, nvidia-cusolver-cu12, aiohttp, torch, shap, pyod, pmdarima, nfoursid, adagio, torchmetrics, tbats, fugue, statsforecast, pytorch-lightning, darts\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "  Attempting uninstall: patsy\n",
      "    Found existing installation: patsy 0.5.6\n",
      "    Uninstalling patsy-0.5.6:\n",
      "      Successfully uninstalled patsy-0.5.6\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "  Attempting uninstall: statsmodels\n",
      "    Found existing installation: statsmodels 0.14.2\n",
      "    Uninstalling statsmodels-0.14.2:\n",
      "      Successfully uninstalled statsmodels-0.14.2\n",
      "Successfully installed Cython-3.0.10 adagio-0.2.4 aiohttp-3.9.5 aiosignal-1.3.1 appdirs-1.4.4 async-timeout-4.0.3 coreforecast-0.0.10 darts-0.25.0 filelock-3.15.4 frozenlist-1.4.1 fs-2.4.16 fsspec-2024.6.1 fugue-0.9.1 holidays-0.52 lightning-utilities-0.11.3.post0 mpmath-1.3.0 multidict-6.0.5 nfoursid-1.0.1 numpy-1.22.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pandas-1.4.4 patsy-0.5.2 pmdarima-2.0.4 pyod-2.0.1 pytorch-lightning-2.3.1 scikit-learn-1.5.0 shap-0.46.0 slicer-0.0.8 statsforecast-1.7.5 statsmodels-0.14.0 sympy-1.12.1 tbats-1.1.3 tensorboardX-2.6.2.2 threadpoolctl-3.5.0 torch-2.3.1 torchmetrics-1.4.0.post0 triad-0.9.8 triton-2.3.1 utilsforecast-0.1.12 xarray-2023.12.0 xgboost-2.1.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install darts==0.25.0 pandas==1.4.4 numpy==1.22.4 patsy==0.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'c8bc209b-93e7-4ba9-a6a7-cb35680e1901', 'key': 'store://parcheggi/dataitems/table/parking_data_aggregated:c8bc209b-93e7-4ba9-a6a7-cb35680e1901', 'kind': 'table', 'metadata': {'created': '2024-07-02T07:42:39.889Z', 'name': 'parking_data_aggregated', 'updated_by': 'tenant1userid', 'project': 'parcheggi', 'version': 'c8bc209b-93e7-4ba9-a6a7-cb35680e1901', 'updated': '2024-07-02T07:42:39.889Z', 'embedded': True, 'created_by': 'tenant1userid'}, 'name': 'parking_data_aggregated', 'project': 'parcheggi', 'spec': {'path': 's3://datalake/parcheggi/dataitems/table/parking_data_aggregated.parquet'}, 'status': {'state': 'CREATED'}, 'user': 'tenant1userid'}, {'id': '8e187428-6f90-499a-a48b-1995b9046ad4', 'key': 'store://parcheggi/dataitems/table/parkings:8e187428-6f90-499a-a48b-1995b9046ad4', 'kind': 'table', 'metadata': {'created': '2024-07-02T07:42:13.144Z', 'name': 'parkings', 'updated_by': 'tenant1userid', 'project': 'parcheggi', 'version': '8e187428-6f90-499a-a48b-1995b9046ad4', 'updated': '2024-07-02T07:42:13.144Z', 'embedded': True, 'created_by': 'tenant1userid'}, 'name': 'parkings', 'project': 'parcheggi', 'spec': {'path': 's3://datalake/parcheggi/dataitems/table/parkings.parquet'}, 'status': {'state': 'CREATED'}, 'user': 'tenant1userid'}, {'id': 'f259bfd4-7a44-4efb-8a2d-43be2f09935f', 'key': 'store://parcheggi/dataitems/table/dataset:f259bfd4-7a44-4efb-8a2d-43be2f09935f', 'kind': 'table', 'metadata': {'created': '2024-07-02T07:41:22.966Z', 'name': 'dataset', 'updated_by': 'tenant1userid', 'project': 'parcheggi', 'version': 'f259bfd4-7a44-4efb-8a2d-43be2f09935f', 'updated': '2024-07-02T07:41:22.966Z', 'embedded': True, 'created_by': 'tenant1userid'}, 'name': 'dataset', 'project': 'parcheggi', 'spec': {'path': 's3://datalake/parcheggi/dataitems/table/dataset.parquet'}, 'status': {'state': 'CREATED'}, 'user': 'tenant1userid'}, {'id': '22f9a253-d426-49d7-9b02-3ce061893d9a', 'key': 'store://parcheggi/dataitems/table/url_data_item:22f9a253-d426-49d7-9b02-3ce061893d9a', 'kind': 'table', 'metadata': {'created': '2024-07-02T07:41:11.426Z', 'name': 'url_data_item', 'updated_by': 'tenant1userid', 'project': 'parcheggi', 'version': '22f9a253-d426-49d7-9b02-3ce061893d9a', 'updated': '2024-07-02T07:41:11.426Z', 'embedded': True, 'created_by': 'tenant1userid'}, 'name': 'url_data_item', 'project': 'parcheggi', 'spec': {'path': 'https://opendata.comune.bologna.it/api/explore/v2.1/catalog/datasets/disponibilita-parcheggi-storico/exports/csv?lang=it&timezone=UTC&use_labels=true&delimiter=%3B'}, 'status': {'state': 'CREATED'}, 'user': 'tenant1userid'}]\n"
     ]
    }
   ],
   "source": [
    "dataitems = dh.list_dataitems(project=\"parcheggi\")\n",
    "print(dataitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcheggio</th>\n",
       "      <th>data</th>\n",
       "      <th>posti_liberi</th>\n",
       "      <th>posti_occupati</th>\n",
       "      <th>posti_totali</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07T01:59:00+00:00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-06-07T02:19:00+00:00</td>\n",
       "      <td>486.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07T02:19:00+00:00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>2024-06-07T02:49:00+00:00</td>\n",
       "      <td>488.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>625</td>\n",
       "      <td>44.500297</td>\n",
       "      <td>11.345368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>2024-06-07T02:49:00+00:00</td>\n",
       "      <td>244.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>265</td>\n",
       "      <td>44.504422</td>\n",
       "      <td>11.346514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     parcheggio                       data  posti_liberi  posti_occupati  \\\n",
       "0  Autostazione  2024-06-07T01:59:00+00:00         244.0            21.0   \n",
       "1   VIII Agosto  2024-06-07T02:19:00+00:00         486.0           139.0   \n",
       "2  Autostazione  2024-06-07T02:19:00+00:00         244.0            21.0   \n",
       "3   VIII Agosto  2024-06-07T02:49:00+00:00         488.0           137.0   \n",
       "4  Autostazione  2024-06-07T02:49:00+00:00         244.0            21.0   \n",
       "\n",
       "   posti_totali        lat        lon  \n",
       "0           265  44.504422  11.346514  \n",
       "1           625  44.500297  11.345368  \n",
       "2           265  44.504422  11.346514  \n",
       "3           625  44.500297  11.345368  \n",
       "4           265  44.504422  11.346514  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import digitalhub as dh\n",
    "\n",
    "dataitem = dh.get_dataitem(project=\"parcheggi\",\n",
    "                           entity_name=\"dataset\")\n",
    "df = dataitem.as_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcheggio</th>\n",
       "      <th>occupied</th>\n",
       "      <th>date_time_slice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>0.079245</td>\n",
       "      <td>2024-06-07 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>2024-06-07 02:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>0.079245</td>\n",
       "      <td>2024-06-07 02:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>2024-06-07 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Autostazione</td>\n",
       "      <td>0.079245</td>\n",
       "      <td>2024-06-07 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9939</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>0.387234</td>\n",
       "      <td>2024-07-01 14:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9940</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>2024-07-01 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9941</th>\n",
       "      <td>VIII Agosto</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>2024-07-01 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9942</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>0.387234</td>\n",
       "      <td>2024-07-01 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9943</th>\n",
       "      <td>Riva Reno</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>2024-07-01 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9792 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        parcheggio  occupied     date_time_slice\n",
       "0     Autostazione  0.079245 2024-06-07 02:00:00\n",
       "1      VIII Agosto  0.222400 2024-06-07 02:30:00\n",
       "2     Autostazione  0.079245 2024-06-07 02:30:00\n",
       "3      VIII Agosto  0.219200 2024-06-07 03:00:00\n",
       "4     Autostazione  0.079245 2024-06-07 03:00:00\n",
       "...            ...       ...                 ...\n",
       "9939     Riva Reno  0.387234 2024-07-01 14:30:00\n",
       "9940     Riva Reno  0.382979 2024-07-01 15:00:00\n",
       "9941   VIII Agosto  0.660800 2024-07-01 15:00:00\n",
       "9942     Riva Reno  0.387234 2024-07-01 15:00:00\n",
       "9943     Riva Reno  0.382979 2024-07-01 15:00:00\n",
       "\n",
       "[9792 rows x 3 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "window = 60\n",
    "\n",
    "df_clean = df.copy()\n",
    "#print(type(df_clean['data'][0]))\n",
    "#df_clean['data'] = pd.to_datetime(df_clean['data'])\n",
    "df_clean.data = pd.to_datetime(df_clean.data, utc=True)\n",
    "#print(type(df_clean['data'][0]))\n",
    "#df_clean.data = df_clean.data.apply(lambda x: x.to_datetime64()) #.astype('datetime64')\n",
    "df_clean['occupied'] = df_clean.posti_occupati / df_clean.posti_totali\n",
    "#df_clean['date_time_slice'] = df_clean.data.dt.round('30min')\n",
    "df_clean['date_time_slice'] = df_clean.data.dt.round('30min').dt.tz_convert(None)\n",
    "df_clean = df_clean[df_clean.date_time_slice >= (datetime.datetime.today() - pd.DateOffset(window))]\n",
    "df_clean = df_clean[df_clean.date_time_slice <= (datetime.datetime.today() - pd.DateOffset(1))]\n",
    "df_clean.posti_occupati = df_clean.apply(lambda x: max(0, min(x['posti_totali'], x['posti_occupati'])), axis=1)\n",
    "df_clean['occupied'] = df_clean.posti_occupati / df_clean.posti_totali\n",
    "df_clean = df_clean.drop(columns=['lat', 'lon', 'data', 'posti_totali', 'posti_liberi', 'posti_occupati'])\n",
    "df_clean#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "                     occupied  hour  dow\n",
      "date_time_slice                         \n",
      "2024-06-07 02:00:00  0.079245     2    4\n",
      "2024-06-07 02:30:00  0.079245     2    4\n",
      "2024-06-07 03:00:00  0.079245     3    4\n",
      "2024-06-07 03:30:00  0.079245     3    4\n",
      "2024-06-07 04:00:00  0.079245     4    4\n",
      "...                       ...   ...  ...\n",
      "2024-07-01 09:30:00  0.207547     9    0\n",
      "2024-07-01 10:00:00  0.216981    10    0\n",
      "2024-07-01 10:30:00  0.250943    10    0\n",
      "2024-07-01 12:00:00  0.286792    12    0\n",
      "2024-07-01 12:30:00  0.286792    12    0\n",
      "\n",
      "[967 rows x 3 columns]\n",
      "###############################\n",
      "after\n",
      "                     occupied  hour  dow\n",
      "date_time_slice                         \n",
      "2024-06-07 02:00:00  0.079245   2.0  4.0\n",
      "2024-06-07 02:30:00  0.079245   2.0  4.0\n",
      "2024-06-07 03:00:00  0.079245   3.0  4.0\n",
      "2024-06-07 03:30:00  0.079245   3.0  4.0\n",
      "2024-06-07 04:00:00  0.079245   4.0  4.0\n",
      "...                       ...   ...  ...\n",
      "2024-07-01 21:30:00  0.147170  21.0  0.0\n",
      "2024-07-01 22:00:00  0.141509  22.0  0.0\n",
      "2024-07-01 22:30:00  0.143396  22.0  0.0\n",
      "2024-07-01 23:00:00  0.133962  23.0  0.0\n",
      "2024-07-01 23:30:00  0.118868  23.0  0.0\n",
      "\n",
      "[1104 rows x 3 columns]\n",
      "###############################\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_759/2908941982.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  parc_df['hour'] = parc_df.date_time_slice.dt.hour\n",
      "/tmp/ipykernel_759/2908941982.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  parc_df['dow'] = parc_df.date_time_slice.dt.dayofweek\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_759/2908941982.py\", line 52, in <module>\n",
      "    train_sets, val_sets = split_dataset(df_clean)\n",
      "  File \"/tmp/ipykernel_759/2908941982.py\", line 43, in split_dataset\n",
      "    ts = TimeSeries.from_dataframe(parc_df,  value_cols='occupied', freq='30min')\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/darts/timeseries.py\", line 720, in from_dataframe\n",
      "    return cls.from_xarray(\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/darts/timeseries.py\", line 385, in from_xarray\n",
      "    xa_ = cls._restore_xarray_from_frequency(xa, freq=freq)\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/darts/timeseries.py\", line 4473, in _restore_xarray_from_frequency\n",
      "    resampled_time_index = resampled_time_index.asfreq(freq)\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/pandas/core/series.py\", line 5695, in asfreq\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/pandas/core/generic.py\", line 8345, in asfreq\n",
      "    Series or DataFrame\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/pandas/core/resample.py\", line 53, in <module>\n",
      "    from pandas.core.base import (\n",
      "ImportError: cannot import name 'DataError' from 'pandas.core.base' (/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/pandas/core/base.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/opt/conda/envs/digitalhub-core/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "\n",
    "split_ratio = 0.8\n",
    "\n",
    "def fill_missing(parc_df):\n",
    "    missing = []  # List to store timestamps for which values could not be filled\n",
    "    temp = pd.Series(parc_df.index.date).value_counts()  # Count the occurrences of each date\n",
    "    temp = temp[temp < 48]  # Filter dates with less than 48 occurrences\n",
    "    temp.sort_index(inplace=True)  # Sort the dates in ascending order\n",
    "    for t in temp.index:  # Iterate through the filtered dates\n",
    "        for h in range(24):  # Iterate through 24 hours\n",
    "            for half_hour in [0, 30]:  # Iterate through 0 and 30 minutes\n",
    "                ts = datetime.datetime(t.year, t.month, t.day, h, half_hour)  # Create a timestamp\n",
    "                if ts not in parc_df.index:  # If the timestamp is missing in the DataFrame\n",
    "                    if ts - datetime.timedelta(days=7) in parc_df.index:  # Check if the previous week's timestamp is available\n",
    "                        parc_df.loc[ts] = parc_df.loc[ts - datetime.timedelta(days=7)].copy()  # Copy values from the previous week\n",
    "                    elif ts + datetime.timedelta(days=7) in parc_df.index:  # Check if the next week's timestamp is available\n",
    "                        parc_df.loc[ts] = parc_df.loc[ts + datetime.timedelta(days=7)].copy()  # Copy values from the next week\n",
    "                    else:\n",
    "                        missing.append(ts)  # If values cannot be filled, add the timestamp to the missing list\n",
    "    return missing \n",
    "\n",
    "\n",
    "def split_dataset(df_clean):\n",
    "    parcheggi = df_clean['parcheggio'].unique()\n",
    "    train_sets, val_sets = [], []\n",
    "\n",
    "    for parcheggio in parcheggi:\n",
    "        parc_df = df_clean[df_clean['parcheggio'] == parcheggio]\n",
    "        parc_df['hour'] = parc_df.date_time_slice.dt.hour\n",
    "        parc_df['dow'] = parc_df.date_time_slice.dt.dayofweek\n",
    "        parc_df = parc_df.drop(columns=['parcheggio'])\n",
    "        parc_df = parc_df.groupby('date_time_slice').agg({'occupied': 'mean', 'hour': 'first', 'dow': 'first'})\n",
    "        \n",
    "        print(\"###############################\")\n",
    "        print(parc_df)\n",
    "        print(\"###############################\")\n",
    "        fill_missing(parc_df)\n",
    "        print(\"after\")\n",
    "        print(parc_df)\n",
    "        print(\"###############################\")\n",
    "        ts = TimeSeries.from_dataframe(parc_df,  value_cols='occupied', freq='30min')\n",
    "        #ts_scaled = Scaler().fit_transform(ts)\n",
    "\n",
    "        #split = int(len(ts_scaled) * (1 - split_ratio))\n",
    "\n",
    "        #train, val = ts_scaled[:-split], ts_scaled[-split:]\n",
    "        #train_sets.append(train)\n",
    "        #val_sets.append(val)\n",
    "    return train_sets,val_sets\n",
    "train_sets, val_sets = split_dataset(df_clean)    \n",
    "#train_sets[0].plot(label='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digitalhub-core",
   "language": "python",
   "name": "digitalhub-core"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
